{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gregory-ch/shap_flex_porting/blob/main/shap_joint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pCGiOaJxKOm"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This module contains using user-defined trained models and prediction functions to compute approximate Shapley values for\n",
        "single models. \n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import csv\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysnQZ3qAYcyM",
        "outputId": "8f068c3d-e855-455e-ac70-d90f360e84ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pd.Series())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-g4zu6ePJNp"
      },
      "outputs": [],
      "source": [
        "class shapFlex_plus:\n",
        "    def __init__(self, explain,  model, predict_function, reference = None, target_features = None, \\\n",
        "                     causal = None, causal_weights = None, sample_size = None, use_future = None):\n",
        "        self.explain = explain\n",
        "        self.reference = reference if reference else explain\n",
        "        self.model = model\n",
        "        predict_function = predict_function\n",
        "        self.target_features = target_features if isinstance(target_features, pd.core.series.Series) else explain.columns.tolist()\n",
        "        self.causal = causal #if causal else None\n",
        "        self.causal_weights = causal_weights #if causal_weights else None\n",
        "        self.sample_size = sample_size if sample_size else 60\n",
        "        self.use_future = use_future if isinstance(target_features, pd.core.series.Series) else False\n",
        "        \n",
        "        self.n_features = self.explain.shape[1]\n",
        "        self.n_instances = self.reference.shape[0]\n",
        "\n",
        "        self.causal_graph = igraph.Graph.DataFrame(self.causal, directed=True) if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v for v in self.causal_graph.vs] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.each_node_causes = {v: v.successors() for v in self.nodes if v.successors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# надо уточнить, мб здесь не только \"прямые\" successors и predecessors ищутся \n",
        "        self.each_node_is_an_effect_from = {v: v.predecessors() for v in nodes if v.predecessors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# но и вообще все\n",
        "        # имена, кажется, уже прописаны автоматически\n",
        "        self.causal_nodes = [v['name'] for v in self.each_node_causes.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.effect_nodes = [v['name'] for v in self.each_node_is_an_effect_from.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def ulist_df(data):\n",
        "      unlisted_df = pd.Series(\n",
        "                  data,\n",
        "                  index=[\n",
        "                  index_col + index_row for index_col, index_row in itertools.product(\n",
        "                      [str(x) for x in range(data.shape[0])], \n",
        "                      [str(x) for x in data.columns])]\n",
        "              )\n",
        "      return unlisted_df\n",
        "      \n",
        "    def loop_over_monte_carlo_samples(self):\n",
        "      i_size = self.sample_size\n",
        "      j_size = len(self.target_features)\n",
        "      data_sample = []\n",
        "      for i in range(i_size):\n",
        "        reference_index = np.random.choice(np.arange(0, self.n_features ), size=1, replace=False)\n",
        "        feature_indices_random = np.random.choice(np.arange(0, self.n_features), size=self.n_features, replace=False)\n",
        "        # r индексация стартует с 1 а питон с 0 поэтому нам нужно вычиать 1 или ставить по верхней границе индексы в зависимости от функции вызова\n",
        "        #reference это pd dataframe\n",
        "        feature_names_random = self.explain.columns[feature_indices_random].values\n",
        "        reference_instance = reference.iloc[reference_index, feature_indices_random]\n",
        "        #feature_indices_random это вектор индексов\n",
        "        explain_instances = explain.iloc[:, feature_indices_random]\n",
        "        data_sample_feature = []\n",
        "        for j in range(j_size):\n",
        "          target_feature_index =  self.explain.columns.get_loc(self.target_features[j])\n",
        "          target_feature_index_shuffled = list(self.explain.columns.values[feature_indices_random]).index(self.target_features[j])\n",
        "          #if True:\n",
        "          #  print(target_feature_index)\n",
        "          # target_feature_index = (self.explain.columns == self.target_features[j])\n",
        "          # target_feature_index_shuffled = (self.explain.columns[feature_indices_random] == self.target_features[j])\n",
        "          \n",
        "          if self.target_features[j] in self.nodes:\n",
        "            #unlist как я понял, вытягивает все данные в один длинный вектор, присваивает индексы как название колонки + название строки\n",
        "            #предположу, что each_node_causes это pd.DataFrame()\n",
        "            target_feature_causes_these_features = self.unlist_df(\n",
        "                #loc потому, что кажется target_features это не индекс\n",
        "                each_node_causes.loc[:, self.target_features[j]]\n",
        "                )\n",
        "            target_feature_is_caused_by = self.unlist_df(\n",
        "                each_node_is_an_effect_from.loc[:, self.target_features[j]]\n",
        "                )\n",
        "            \n",
        "            target_index = target_feature_index_shuffled\n",
        "            #отмечаем те значения feature_names_random которые равны последнему значению \n",
        "            #target_feature_is_caused_by. target_feature_is_caused_by вроде как вектор\n",
        "            #вернуться должно число. Если вдруг окажется, что датафрейм, -1 элемент будет строка, \n",
        "            #надо заменить на индексацию на iloc, == на .isin\n",
        "            causes_indices = (feature_names_random == target_feature_is_caused_by[-1])\n",
        "            effects_indices = (feature_names_random == target_feature_causes_these_features[-1])\n",
        "            sample_indices = feature_indices_random[~feature_indices_random.isin(\n",
        "                np.concatenate([target_index, causes_indices, effects_indices]))]\n",
        "            #c() вроде как склеивает вектор(ы) и переменные\n",
        "            sample_real_indices = sample_indices[sample_indices < target_index]  # Not in causal diagram, feature data from 'explain'.\n",
        "            sample_fake_indices = sample_indices[sample_indices > target_index]  # Not in causal diagram, feature data from 'reference'.\n",
        "\n",
        "            feature_indices_real_causes_real_effects = np.concatenate([sample_real_indices, causes_indices, effects_indices, target_index, sample_fake_indices], ignore_index=True)\n",
        "            feature_indices_real_causes_fake_effects = np.concatenate([sample_real_indices, causes_indices, target_index, effects_indices, sample_fake_indices], ignore_index=True)\n",
        "            feature_indices_fake_causes_real_effects = np.concatenate([sample_real_indices, effects_indices, target_index, causes_indices, sample_fake_indices], ignore_index=True)\n",
        "            feature_indices_fake_causes_fake_effects = np.concatenate([sample_real_indices, target_index, causes_indices, effects_indices, sample_fake_indices], ignore_index=True)\n",
        "          \n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            explain_instance_real_target = explain_instances\n",
        "\n",
        "            # Only create a Frankenstein instance if the target is not the last feature and there is actually\n",
        "            # one or more features to the right of the target to replace with the reference.\n",
        "            if (target_feature_index_shuffled < self.n_features):\n",
        "              explain_instance_real_target.iloc[:, target_feature_index_shuffled + 1: self.n_features + 1] =\\\n",
        "              reference_instance.iloc[:, target_feature_index_shuffled + 1: self.n_features + 1]\n",
        "            \n",
        "            # These instances are otherwise the same as the Frankenstein instance created above with the\n",
        "            # exception that the target feature is now replaced with the target feature in the random reference\n",
        "            # instance. The difference in model predictions between these two Frankenstein instances is\n",
        "            # what gives us the stochastic Shapley value approximation.\n",
        "            explain_instance_fake_target = explain_instance_real_target\n",
        "            # если не ставить target_feature_index_shuffled в квадратные скобки, не выполняется бродкастинг\n",
        "            explain_instance_fake_target.iloc[:, [target_feature_index_shuffled]] = reference_instance.iloc[:, [target_feature_index_shuffled]]\n",
        "          \n",
        "          else:\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              target_index_temp = (explain_instance_real_causes_fake_effects_real_target.columns.values == self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_real_causes_fake_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]\n",
        "\n",
        "              explain_instance_real_causes_fake_effects_fake_target = explain_instance_real_causes_fake_effects_real_target\n",
        "              explain_instance_real_causes_fake_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = (explain_instance_fake_causes_real_effects_real_target_cause.columns.values == self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_fake_causes_real_effects[:, target_index_temp + 1: self.n_features]\n",
        "              \n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause = explain_instance_fake_causes_real_effects_real_target_cause\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              target_index_temp = (explain_instance_real_causes_fake_effects_real_target_effect.columns.values == self.target_features[j])\n",
        "\n",
        "              if (target_index_temp < self.n_features):\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]\n",
        "              \n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect = explain_instance_real_causes_fake_effects_real_target_effect\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = (explain_instance_fake_causes_real_effects_real_target.columns.values == self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features + 1]\n",
        "\n",
        "              explain_instance_fake_causes_real_effects_fake_target = explain_instance_fake_causes_real_effects_real_target\n",
        "              explain_instance_fake_causes_real_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]\n",
        "\n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            explain_instance_real_target = explain_instance_real_target.loc[:, explain.columns]\n",
        "            explain_instance_fake_target = explain_instance_fake_target.loc[:, explain.columns]\n",
        "            data_explain_instance = pd.concat([explain_instance_real_target, explain_instance_fake_target], axis=0).reset_index(drop=True)#, ignore_index=True)\n",
        "            #вот тут не совсем понятно, индекс это число или строка, индексы в data_explain_instance это числа или строки? в любом случае, при запуске можно починить\n",
        "            data_explain_instance['index'] = np.tile(np.arange(1, explain.shape[0] + 1), 2) \n",
        "            data_explain_instance['feature_group'] = np.tile(pd.Series(['real_target', 'fake_target']), explain.shape[0])\n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 0\n",
        "            data_explain_instance['causal_type'] = None\n",
        "\n",
        "          else:\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target.loc[:, explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target.loc[:, explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause.loc[:, explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.loc[:, explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect.loc[:, explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.loc[:, explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target.loc[:, explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target.loc[:, explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause], axis=0\n",
        "              ).reset_index(drop=True)\n",
        "              data_explain_instance[index] = np.tile(np.arange(1, explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance[feature_group] = np.tile(pd.Series([\"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",\n",
        "                                                          \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\"]),\n",
        "                                                        explain.shape[0])\n",
        "              data_explain_instance[causal_type] = \"target_is_a_cause\"\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance[index] = np.tile(np.arange(1, explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance[feature_group] = np.tile(pd.Series([\"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",\n",
        "                                                          \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"]),\n",
        "                                                        explain.shape[0])\n",
        "              data_explain_instance[causal_type] = \"target_is_an_effect\"\n",
        "\n",
        "            if (self.target_features[j] in self.causal_nodes) and (self.target_features[j] in self.effect_nodes):\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause,\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, explain.shape[0] + 1), 8)  # Eight Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\n",
        "                \"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",  # Target is a causal node.\n",
        "                \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\",  # Target is a causal node.\n",
        "                \"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",  # Target is an effect node.\n",
        "                \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"  # Target is an effect node.\n",
        "                ]),\n",
        "              explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = np.tile(pd.Series([\n",
        "                \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\",\n",
        "                \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\"]\n",
        "              ),\n",
        "              explain.shape[0])\n",
        "            \n",
        "            data_explain_instance['feature_name'] = target_features[j]\n",
        "            data_explain_instance[causal] = 1\n",
        "\n",
        "            data_explain_instance['sample'] = i\n",
        "            data_explain_instance\n",
        "\n",
        "        \n",
        "          data_sample_feature.append(data_explain_instance)\n",
        "          data_sample_feature\n",
        "        data_sample.append(data_sample_feature)\n",
        "        #STOP\n",
        "      data_sample = pd.concat([pd.concat(data_sample_i, axis=0) for data_sample_i in data_sample], axis=0)\n",
        "      return data_sample\n",
        "\n",
        "                        \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvv8L5zPqeJf"
      },
      "source": [
        "1) текущий раздел работы строки: 125-397, в строках инициализируется функция сэмплирования, проходит по двум петлям цикла. [закончено]\n",
        "2) Начало цикла [закончено]\n",
        "\n",
        "3) \"Франкенштейна\" cтр 172 -270 [закончено]\n",
        " \n",
        "4) Цикл i loop, j loop  стр 397 [закончено]\n",
        "\n",
        "5) написан код для инициализации объектов на вход в класс: модель, обработку данных, предикт функцию. Датасет в csv на гугл-диск кинул: https://drive.google.com/file/d/1ADJ2yNZum-quPW3bRWJ4iyEa2OoqlS18/view?usp=sharing, пока для простоты складывается в файлы колаба через drag-and-drop.\n",
        "\n",
        "6) Инициализация графа [закончено]\n",
        "\n",
        "7) В основном разделе R/shapFlex дошли до вызова функции predict_shapFlex на 401 стр., проверили инициализацию класса ShapFlex_plus начали отладку запуска loop_over_monte_carlo_samples()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-7swqKojM7F"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#data = pd.read_csv('/content/data_adult.csv', index_col=0)\n",
        "data = pd.read_csv('https://kolodezev.ru/download/data_adult.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0aqnQ8ejXZl",
        "outputId": "27196a61-3791-4d92-d10e-99594ac35f78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=300, random_state=42)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder = OneHotEncoder()\n",
        "outcome_name = 'income'\n",
        "outcome_col = pd.Series(data.columns)[data.columns==outcome_name].index[0]\n",
        "model = RandomForestClassifier(n_estimators=300, random_state=42)\n",
        "X, y = data.drop(outcome_name, axis=1), data[outcome_name].values\n",
        "X, y = pd.get_dummies(X, drop_first=True), np.array([1 if x == '<=50K' else 0 for x in y ]).ravel()\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPp1OsnmjZIL"
      },
      "outputs": [],
      "source": [
        "def predict_function(model, data):\n",
        "  #pd.DataFrame(model.predict_proba(X)).loc[:, 0][9] если запустить будет результат 0.98, что соответствует\n",
        "  #выводу для 9 номера который равен 0.98, неважно какой алгоритм, такая высокая степень уверенности\n",
        "  #позволяет идентифицировать выводимую колонку однозначно\n",
        "  X, y = data.drop(outcome_name, axis=1), data[outcome_name].values\n",
        "  X, y = pd.get_dummies(X, drop_first=True), np.array([1 if x == '<=50K' else 0 for x in y ]).ravel()\n",
        "  return pd.DataFrame(model.predict_proba(X)).loc[:, 0], X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFDEC0YUjr4V"
      },
      "outputs": [],
      "source": [
        "explain, reference = data.iloc[:350, :data.shape[1]-1], data.iloc[:, :data.shape[1]-1]\n",
        "sample_size = 60\n",
        "target_features = pd.Series([\"marital_status\", \"education\", \"relationship\",  \"native_country\",\n",
        "                     \"age\", \"sex\", \"race\", \"hours_per_week\"])\n",
        "causal = pd.DataFrame(\n",
        "  dict(cause=pd.Series([\"age\", \"sex\", \"race\", \"native_country\",\n",
        "              \"age\", \"sex\", \"race\", \"native_country\", \"age\",\n",
        "              \"sex\", \"race\", \"native_country\"]),\n",
        "  effect = pd.Series(np.concatenate([np.tile(\"marital_status\", 4), np.tile(\"education\", 4), np.tile(\"relationship\", 4)])))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RslJjzLYjs-4",
        "outputId": "e97b13bb-2190-4b40-8239-878a66acf83c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting igraph\n",
            "  Downloading igraph-0.9.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable, igraph\n",
            "Successfully installed igraph-0.9.9 texttable-1.6.4\n"
          ]
        }
      ],
      "source": [
        "!pip install igraph\n",
        "import igraph\n",
        "causal_graph = igraph.Graph.DataFrame(causal, directed=True)\n",
        "nodes = [v for v in causal_graph.vs]\n",
        "each_node_causes = {v: v.successors() for v in nodes if v.successors()}# надо уточнить, мб здесь не только \"прямые\" successors и predecessors ищутся \n",
        "each_node_is_an_effect_from = {v: v.predecessors() for v in nodes if v.predecessors()} # но и вообще все\n",
        "# имена, кажется, уже прописаны автоматически\n",
        "causal_nodes = [v['name'] for v in each_node_causes.keys()]\n",
        "effect_nodes = [v['name'] for v in each_node_is_an_effect_from.keys()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsKJfNYYOjUs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq8NFfDkmQAO"
      },
      "source": [
        "# Новый раздел"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "I_mTNuEJcwr-",
        "outputId": "a0f6e658-3d95-4e90-b7d1-a339ec7bea34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-55403b2e-a7ca-4a49-a8cf-369a011b9dbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55403b2e-a7ca-4a49-a8cf-369a011b9dbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55403b2e-a7ca-4a49-a8cf-369a011b9dbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55403b2e-a7ca-4a49-a8cf-369a011b9dbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age         workclass  ... hours_per_week  native_country\n",
              "0   39         State-gov  ...             40   United-States\n",
              "1   50  Self-emp-not-inc  ...             13   United-States\n",
              "2   38           Private  ...             40   United-States\n",
              "3   53           Private  ...             40   United-States\n",
              "4   28           Private  ...             40            Cuba\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDvjYe2scxq1"
      },
      "outputs": [],
      "source": [
        "exmpl_of_test = shapFlex_plus(explain,  model, predict_function, target_features=pd.Series([\"marital_status\", \"education\", \"relationship\", \"native_country\",\n",
        "\"age\", \"sex\", \"race\", \"hours_per_week\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1CgvQGw_DUk"
      },
      "outputs": [],
      "source": [
        "\n",
        "result = exmpl_of_test.loop_over_monte_carlo_samples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "gW2KzM9YqLU8",
        "outputId": "237a76ba-c821-4ee7-8e03-72a4e752bc89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-168766f9-cd56-4916-b8d1-77cbfb99ba45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>index</th>\n",
              "      <th>feature_group</th>\n",
              "      <th>feature_name</th>\n",
              "      <th>causal</th>\n",
              "      <th>causal_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>real_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50.0</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>2</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>3</td>\n",
              "      <td>real_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>4</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>5</td>\n",
              "      <td>real_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>346</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>347</td>\n",
              "      <td>real_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>348</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>349</td>\n",
              "      <td>real_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>350</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>336000 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-168766f9-cd56-4916-b8d1-77cbfb99ba45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-168766f9-cd56-4916-b8d1-77cbfb99ba45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-168766f9-cd56-4916-b8d1-77cbfb99ba45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      age         workclass  education  ...    feature_name causal causal_type\n",
              "0    39.0         State-gov  Bachelors  ...  marital_status      0        None\n",
              "1    50.0  Self-emp-not-inc  Bachelors  ...  marital_status      0        None\n",
              "2    38.0           Private    HS-grad  ...  marital_status      0        None\n",
              "3    53.0           Private       11th  ...  marital_status      0        None\n",
              "4    28.0           Private  Bachelors  ...  marital_status      0        None\n",
              "..    ...               ...        ...  ...             ...    ...         ...\n",
              "695   NaN               NaN        NaN  ...  hours_per_week      0        None\n",
              "696   NaN               NaN        NaN  ...  hours_per_week      0        None\n",
              "697   NaN               NaN        NaN  ...  hours_per_week      0        None\n",
              "698   NaN               NaN        NaN  ...  hours_per_week      0        None\n",
              "699   NaN               NaN        NaN  ...  hours_per_week      0        None\n",
              "\n",
              "[336000 rows x 18 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6elIp1FWipFi",
        "outputId": "ddf24118-f611-4693-d045-cd8c55fc013c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-51-d9ac69c401e4>\u001b[0m(231)\u001b[0;36mloop_over_monte_carlo_samples\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    229 \u001b[0;31m          \u001b[0mdata_sample_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    230 \u001b[0;31m        \u001b[0mdata_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 231 \u001b[0;31m        \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    232 \u001b[0;31m      \u001b[0mdata_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_sample_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    233 \u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0mdata_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "[      age  workclass  education  ...    feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  marital_status      0        None\n",
            "1     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "2     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "3     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "4     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "..    ...        ...        ...  ...             ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "346   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "347   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "348   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "349   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...     education      0        None\n",
            "1     NaN        NaN        NaN  ...     education      0        None\n",
            "2     NaN        NaN        NaN  ...     education      0        None\n",
            "3     NaN        NaN        NaN  ...     education      0        None\n",
            "4     NaN        NaN        NaN  ...     education      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...     education      0        None\n",
            "346   NaN        NaN        NaN  ...     education      0        None\n",
            "347   NaN        NaN        NaN  ...     education      0        None\n",
            "348   NaN        NaN        NaN  ...     education      0        None\n",
            "349   NaN        NaN        NaN  ...     education      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  relationship      0        None\n",
            "1     NaN        NaN        NaN  ...  relationship      0        None\n",
            "2     NaN        NaN        NaN  ...  relationship      0        None\n",
            "3     NaN        NaN        NaN  ...  relationship      0        None\n",
            "4     NaN        NaN        NaN  ...  relationship      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  relationship      0        None\n",
            "346   NaN        NaN        NaN  ...  relationship      0        None\n",
            "347   NaN        NaN        NaN  ...  relationship      0        None\n",
            "348   NaN        NaN        NaN  ...  relationship      0        None\n",
            "349   NaN        NaN        NaN  ...  relationship      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...    feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  native_country      0        None\n",
            "1     NaN        NaN        NaN  ...  native_country      0        None\n",
            "2     NaN        NaN        NaN  ...  native_country      0        None\n",
            "3     NaN        NaN        NaN  ...  native_country      0        None\n",
            "4     NaN        NaN        NaN  ...  native_country      0        None\n",
            "..    ...        ...        ...  ...             ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  native_country      0        None\n",
            "346   NaN        NaN        NaN  ...  native_country      0        None\n",
            "347   NaN        NaN        NaN  ...  native_country      0        None\n",
            "348   NaN        NaN        NaN  ...  native_country      0        None\n",
            "349   NaN        NaN        NaN  ...  native_country      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...           age      0        None\n",
            "1     NaN        NaN        NaN  ...           age      0        None\n",
            "2     NaN        NaN        NaN  ...           age      0        None\n",
            "3     NaN        NaN        NaN  ...           age      0        None\n",
            "4     NaN        NaN        NaN  ...           age      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...           age      0        None\n",
            "346   NaN        NaN        NaN  ...           age      0        None\n",
            "347   NaN        NaN        NaN  ...           age      0        None\n",
            "348   NaN        NaN        NaN  ...           age      0        None\n",
            "349   NaN        NaN        NaN  ...           age      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...           sex      0        None\n",
            "1     NaN        NaN        NaN  ...           sex      0        None\n",
            "2     NaN        NaN        NaN  ...           sex      0        None\n",
            "3     NaN        NaN        NaN  ...           sex      0        None\n",
            "4     NaN        NaN        NaN  ...           sex      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...           sex      0        None\n",
            "346   NaN        NaN        NaN  ...           sex      0        None\n",
            "347   NaN        NaN        NaN  ...           sex      0        None\n",
            "348   NaN        NaN        NaN  ...           sex      0        None\n",
            "349   NaN        NaN        NaN  ...           sex      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...          race      0        None\n",
            "1     NaN        NaN        NaN  ...          race      0        None\n",
            "2     NaN        NaN        NaN  ...          race      0        None\n",
            "3     NaN        NaN        NaN  ...          race      0        None\n",
            "4     NaN        NaN        NaN  ...          race      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...          race      0        None\n",
            "346   NaN        NaN        NaN  ...          race      0        None\n",
            "347   NaN        NaN        NaN  ...          race      0        None\n",
            "348   NaN        NaN        NaN  ...          race      0        None\n",
            "349   NaN        NaN        NaN  ...          race      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...    feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  hours_per_week      0        None\n",
            "1     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "2     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "3     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "4     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "..    ...        ...        ...  ...             ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "346   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "347   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "348   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "349   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "\n",
            "[700 rows x 18 columns]]\n",
            "\n",
            "Documented commands (type help <topic>):\n",
            "========================================\n",
            "EOF    cl         disable  interact  next    psource  rv         unt   \n",
            "a      clear      display  j         p       q        s          until \n",
            "alias  commands   down     jump      pdef    quit     source     up    \n",
            "args   condition  enable   l         pdoc    r        step       w     \n",
            "b      cont       exit     list      pfile   restart  tbreak     whatis\n",
            "break  continue   h        ll        pinfo   return   u          where \n",
            "bt     d          help     longlist  pinfo2  retval   unalias  \n",
            "c      debug      ignore   n         pp      run      undisplay\n",
            "\n",
            "Miscellaneous help topics:\n",
            "==========================\n",
            "exec  pdb\n",
            "\n",
            "[      age  workclass  education  ...    feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  marital_status      0        None\n",
            "1     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "2     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "3     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "4     NaN        NaN        NaN  ...  marital_status      0        None\n",
            "..    ...        ...        ...  ...             ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "346   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "347   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "348   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "349   NaN        NaN        NaN  ...  marital_status      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...     education      0        None\n",
            "1     NaN        NaN        NaN  ...     education      0        None\n",
            "2     NaN        NaN        NaN  ...     education      0        None\n",
            "3     NaN        NaN        NaN  ...     education      0        None\n",
            "4     NaN        NaN        NaN  ...     education      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...     education      0        None\n",
            "346   NaN        NaN        NaN  ...     education      0        None\n",
            "347   NaN        NaN        NaN  ...     education      0        None\n",
            "348   NaN        NaN        NaN  ...     education      0        None\n",
            "349   NaN        NaN        NaN  ...     education      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  relationship      0        None\n",
            "1     NaN        NaN        NaN  ...  relationship      0        None\n",
            "2     NaN        NaN        NaN  ...  relationship      0        None\n",
            "3     NaN        NaN        NaN  ...  relationship      0        None\n",
            "4     NaN        NaN        NaN  ...  relationship      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  relationship      0        None\n",
            "346   NaN        NaN        NaN  ...  relationship      0        None\n",
            "347   NaN        NaN        NaN  ...  relationship      0        None\n",
            "348   NaN        NaN        NaN  ...  relationship      0        None\n",
            "349   NaN        NaN        NaN  ...  relationship      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...    feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  native_country      0        None\n",
            "1     NaN        NaN        NaN  ...  native_country      0        None\n",
            "2     NaN        NaN        NaN  ...  native_country      0        None\n",
            "3     NaN        NaN        NaN  ...  native_country      0        None\n",
            "4     NaN        NaN        NaN  ...  native_country      0        None\n",
            "..    ...        ...        ...  ...             ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  native_country      0        None\n",
            "346   NaN        NaN        NaN  ...  native_country      0        None\n",
            "347   NaN        NaN        NaN  ...  native_country      0        None\n",
            "348   NaN        NaN        NaN  ...  native_country      0        None\n",
            "349   NaN        NaN        NaN  ...  native_country      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...           age      0        None\n",
            "1     NaN        NaN        NaN  ...           age      0        None\n",
            "2     NaN        NaN        NaN  ...           age      0        None\n",
            "3     NaN        NaN        NaN  ...           age      0        None\n",
            "4     NaN        NaN        NaN  ...           age      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...           age      0        None\n",
            "346   NaN        NaN        NaN  ...           age      0        None\n",
            "347   NaN        NaN        NaN  ...           age      0        None\n",
            "348   NaN        NaN        NaN  ...           age      0        None\n",
            "349   NaN        NaN        NaN  ...           age      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...           sex      0        None\n",
            "1     NaN        NaN        NaN  ...           sex      0        None\n",
            "2     NaN        NaN        NaN  ...           sex      0        None\n",
            "3     NaN        NaN        NaN  ...           sex      0        None\n",
            "4     NaN        NaN        NaN  ...           sex      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...           sex      0        None\n",
            "346   NaN        NaN        NaN  ...           sex      0        None\n",
            "347   NaN        NaN        NaN  ...           sex      0        None\n",
            "348   NaN        NaN        NaN  ...           sex      0        None\n",
            "349   NaN        NaN        NaN  ...           sex      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...  feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...          race      0        None\n",
            "1     NaN        NaN        NaN  ...          race      0        None\n",
            "2     NaN        NaN        NaN  ...          race      0        None\n",
            "3     NaN        NaN        NaN  ...          race      0        None\n",
            "4     NaN        NaN        NaN  ...          race      0        None\n",
            "..    ...        ...        ...  ...           ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...          race      0        None\n",
            "346   NaN        NaN        NaN  ...          race      0        None\n",
            "347   NaN        NaN        NaN  ...          race      0        None\n",
            "348   NaN        NaN        NaN  ...          race      0        None\n",
            "349   NaN        NaN        NaN  ...          race      0        None\n",
            "\n",
            "[700 rows x 18 columns],       age  workclass  education  ...    feature_name causal causal_type\n",
            "0    39.0  State-gov  Bachelors  ...  hours_per_week      0        None\n",
            "1     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "2     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "3     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "4     NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "..    ...        ...        ...  ...             ...    ...         ...\n",
            "345   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "346   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "347   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "348   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "349   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "\n",
            "[700 rows x 18 columns]]\n",
            "*** AttributeError: 'list' object has no attribute 'shape'\n",
            "8\n",
            "(700, 18)\n",
            "    age  workclass  education  ...    feature_name causal causal_type\n",
            "0  39.0  State-gov  Bachelors  ...  hours_per_week      0        None\n",
            "1   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "2   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "3   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "4   NaN        NaN        NaN  ...  hours_per_week      0        None\n",
            "\n",
            "[5 rows x 18 columns]\n",
            "Empty DataFrame\n",
            "Columns: [age, workclass, education, education_num, marital_status, occupation, relationship, race, sex, capital_gain, capital_loss, hours_per_week, native_country, index, feature_group, feature_name, causal, causal_type]\n",
            "Index: []\n",
            "    age  workclass  education  ...    feature_name causal causal_type\n",
            "0  39.0  State-gov  Bachelors  ...  hours_per_week      0        None\n",
            "\n",
            "[1 rows x 18 columns]\n"
          ]
        }
      ],
      "source": [
        "%debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "sus7B5wWtYax",
        "outputId": "24430006-74a6-4ed5-edf7-5c1f01753e91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9a36c213-f892-41d3-81bb-18e07416d53e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>index</th>\n",
              "      <th>feature_group</th>\n",
              "      <th>feature_name</th>\n",
              "      <th>causal</th>\n",
              "      <th>causal_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>22.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>345</td>\n",
              "      <td>real_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>43.0</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>346</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>67.0</td>\n",
              "      <td>?</td>\n",
              "      <td>11th</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>?</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>347</td>\n",
              "      <td>real_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>30.0</td>\n",
              "      <td>?</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>?</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>348</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>56.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>Iran</td>\n",
              "      <td>349</td>\n",
              "      <td>real_target</td>\n",
              "      <td>marital_status</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>346</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>347</td>\n",
              "      <td>real_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>348</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>349</td>\n",
              "      <td>real_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>350</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>335656 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a36c213-f892-41d3-81bb-18e07416d53e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a36c213-f892-41d3-81bb-18e07416d53e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a36c213-f892-41d3-81bb-18e07416d53e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      age         workclass     education  ...    feature_name causal causal_type\n",
              "344  22.0         State-gov  Some-college  ...  marital_status      0        None\n",
              "345  43.0  Self-emp-not-inc     Bachelors  ...  marital_status      0        None\n",
              "346  67.0                 ?          11th  ...  marital_status      0        None\n",
              "347  30.0                 ?     Assoc-voc  ...  marital_status      0        None\n",
              "348  56.0           Private    Assoc-acdm  ...  marital_status      0        None\n",
              "..    ...               ...           ...  ...             ...    ...         ...\n",
              "345   NaN               NaN           NaN  ...  hours_per_week      0        None\n",
              "346   NaN               NaN           NaN  ...  hours_per_week      0        None\n",
              "347   NaN               NaN           NaN  ...  hours_per_week      0        None\n",
              "348   NaN               NaN           NaN  ...  hours_per_week      0        None\n",
              "349   NaN               NaN           NaN  ...  hours_per_week      0        None\n",
              "\n",
              "[335656 rows x 18 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.iloc[344:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yg1qapCo63h",
        "outputId": "c52d2bb1-86ae-497b-9533-5e2825b25f01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exmpl_of_test.n_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "IS0l12m0lJbs",
        "outputId": "7d68c4bb-4443-4753-b7b1-6680efda4532"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-460da444203f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "result[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfkFWCjEkjAs",
        "outputId": "c0fad7f0-cc8d-47b2-9e93-90c827b4d98d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2.0, 700.0)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "avg_rows_age_not_na = []\n",
        "avg_shape = []\n",
        "for i in range(len(result)):\n",
        "  for j in range(len(result[i])):\n",
        "    avg_rows_age_not_na += [result[i][j].loc[~result[i][j].age.isna()].shape[0]]\n",
        "    avg_shape += [result[i][j].shape[0]]\n",
        "\n",
        "np.mean(avg_rows_age_not_na), np.mean(avg_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEarMNX-heRo"
      },
      "outputs": [],
      "source": [
        "result = result.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "ADl36pIxiDru",
        "outputId": "0a211a90-000c-4cc6-d002-672dc2a51f69"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd0d46ca-5210-4e40-bb39-e1b4021d6838\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>index</th>\n",
              "      <th>feature_group</th>\n",
              "      <th>feature_name</th>\n",
              "      <th>causal</th>\n",
              "      <th>causal_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>real_target</td>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>real_target</td>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700</th>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>real_target</td>\n",
              "      <td>workclass</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>real_target</td>\n",
              "      <td>workclass</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>real_target</td>\n",
              "      <td>education</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544255</th>\n",
              "      <td>5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>6</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>capital_loss</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544605</th>\n",
              "      <td>5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>6</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544955</th>\n",
              "      <td>5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>6</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545305</th>\n",
              "      <td>5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>6</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>native_country</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545655</th>\n",
              "      <td>5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>6</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>native_country</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1560 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd0d46ca-5210-4e40-bb39-e1b4021d6838')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd0d46ca-5210-4e40-bb39-e1b4021d6838 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd0d46ca-5210-4e40-bb39-e1b4021d6838');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        level_0   age  workclass  ...    feature_name  causal causal_type\n",
              "0             0  39.0  State-gov  ...             age       0        None\n",
              "350           0  39.0  State-gov  ...             age       0        None\n",
              "700           0  39.0  State-gov  ...       workclass       0        None\n",
              "1050          0  39.0  State-gov  ...       workclass       0        None\n",
              "1400          0  39.0  State-gov  ...       education       0        None\n",
              "...         ...   ...        ...  ...             ...     ...         ...\n",
              "544255        5  37.0    Private  ...    capital_loss       0        None\n",
              "544605        5  37.0    Private  ...  hours_per_week       0        None\n",
              "544955        5  37.0    Private  ...  hours_per_week       0        None\n",
              "545305        5  37.0    Private  ...  native_country       0        None\n",
              "545655        5  37.0    Private  ...  native_country       0        None\n",
              "\n",
              "[1560 rows x 19 columns]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.loc[~result.age.isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Bx5CHwgbco",
        "outputId": "50f95736-0185-4865-88c1-0894b0c08819"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "350.0    1506\n",
              "351.0       8\n",
              "348.0       5\n",
              "352.0       5\n",
              "355.0       4\n",
              "346.0       4\n",
              "343.0       3\n",
              "349.0       3\n",
              "353.0       3\n",
              "358.0       3\n",
              "344.0       3\n",
              "345.0       3\n",
              "356.0       2\n",
              "359.0       1\n",
              "339.0       1\n",
              "361.0       1\n",
              "338.0       1\n",
              "347.0       1\n",
              "357.0       1\n",
              "354.0       1\n",
              "dtype: int64"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(result.loc[~result.age.isna()].index[::-1].values).rolling(2).apply(lambda x: x.iloc[0]-x.iloc[1]).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqCUZdEgeLyX",
        "outputId": "ac2240f5-6a0e-4f68-e730-a82da4122c69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((468000, 3), (468000, 15), (468000, 18))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.iloc[:, :3].shape, result.iloc[:, 3:].shape, result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "PmKPrtyVZxq8",
        "outputId": "c7f9d277-9ab0-49a6-b731-ed5c816fb97d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ce1838a8-5986-4148-a267-ea27c702ad3a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>index</th>\n",
              "      <th>feature_group</th>\n",
              "      <th>feature_name</th>\n",
              "      <th>causal</th>\n",
              "      <th>causal_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>1</td>\n",
              "      <td>real_target</td>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>2</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>3</td>\n",
              "      <td>real_target</td>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "      <td>4</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>5</td>\n",
              "      <td>real_target</td>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>296</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>native_country</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>297</td>\n",
              "      <td>real_target</td>\n",
              "      <td>native_country</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>298</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>native_country</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>299</td>\n",
              "      <td>real_target</td>\n",
              "      <td>native_country</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>300</td>\n",
              "      <td>fake_target</td>\n",
              "      <td>native_country</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>468000 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce1838a8-5986-4148-a267-ea27c702ad3a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce1838a8-5986-4148-a267-ea27c702ad3a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce1838a8-5986-4148-a267-ea27c702ad3a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     age         workclass  education  ...    feature_name causal causal_type\n",
              "0    NaN         State-gov  Bachelors  ...             age      0        None\n",
              "1    NaN  Self-emp-not-inc  Bachelors  ...             age      0        None\n",
              "2    NaN           Private    HS-grad  ...             age      0        None\n",
              "3    NaN           Private       11th  ...             age      0        None\n",
              "4    NaN           Private  Bachelors  ...             age      0        None\n",
              "..   ...               ...        ...  ...             ...    ...         ...\n",
              "295  NaN               NaN        NaN  ...  native_country      0        None\n",
              "296  NaN               NaN        NaN  ...  native_country      0        None\n",
              "297  NaN               NaN        NaN  ...  native_country      0        None\n",
              "298  NaN               NaN        NaN  ...  native_country      0        None\n",
              "299  NaN               NaN        NaN  ...  native_country      0        None\n",
              "\n",
              "[468000 rows x 18 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def predict_shapFlex(reference, data_predict, model, predict_function, n_features, causal, causal_weights):\n",
        "   data_model = data_predict.iloc[:, :n_features]\n",
        "   data_meta = data_predict.iloc[:, n_features:]\n",
        "   data_predicted = predict_function(model, data_model)\n",
        "   data_predicted = pd.concat([data_meta, data_predicted], axis=1)\n",
        "   intercept = predict_function(model, reference)[0].mean()\n",
        "   user_fun_y_pred_name = names(data_predicted)[ncol(data_predicted)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_JPkut0ndlZ",
        "outputId": "5092f26b-3ef2-4285-af7a-3d79c6e4fd5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "576"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "288*2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKFXP6gpi3jH",
        "outputId": "96aee1cf-e98e-462f-9590-8040b539f19e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "x = pd.DataFrame(\n",
        "  dict(cause=pd.Series([\"age\", \"sex\", \"race\", \"native_country\",\n",
        "              \"age\", \"sex\", \"race\", \"native_country\", \"age\",\n",
        "              \"sex\", \"race\", \"native_country\"]),\n",
        "  effect = pd.Series(np.concatenate([np.tile(\"marital_status\", 4), np.tile(\"education\", 4), np.tile(\"relationship\", 4)])))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 24/03/2022\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import igraph\n",
        "import itertools\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "class shapFlex_plus:\n",
        "    def __init__(self, explain,  model, predict_function, reference = None, target_features = None, \\\n",
        "                     causal = None, causal_weights = None, sample_size = None, use_future = None):\n",
        "        self.explain = explain\n",
        "        self.reference = reference if reference else explain\n",
        "        self.model = model\n",
        "        self.predict_function = predict_function\n",
        "        self.target_features = target_features if isinstance(target_features, pd.core.series.Series) else explain.columns.tolist()\n",
        "        self.causal = causal #if causal else None\n",
        "        self.causal_weights = causal_weights #if causal_weights else None\n",
        "        self.sample_size = sample_size if sample_size else 60\n",
        "        self.use_future = use_future if isinstance(target_features, pd.core.series.Series) else False\n",
        "        \n",
        "        self.n_features = self.explain.shape[1]\n",
        "        self.n_instances = self.reference.shape[0]\n",
        "\n",
        "        self.causal_graph = igraph.Graph.DataFrame(self.causal, directed=True) if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v for v in self.causal_graph.vs] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.each_node_causes = {v['name']: [succ['name'] for succ in v.successors()] for v in self.nodes if v.successors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# надо уточнить, мб здесь не только \"прямые\" successors и predecessors ищутся \n",
        "        self.each_node_is_an_effect_from = {v['name']: [pred['name'] for pred in v.predecessors()] for v in self.nodes if v.predecessors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# но и вообще все\n",
        "        # имена, кажется, уже прописаны автоматически\n",
        "        self.causal_nodes = [v for v in self.each_node_causes.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.effect_nodes = [v for v in self.each_node_is_an_effect_from.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v['name'] for v in self.nodes] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "\n",
        "    @staticmethod\n",
        "    def unlist_df(data):\n",
        "      unlisted_df = pd.Series(\n",
        "                  data,\n",
        "                  index=[\n",
        "                  index_col + index_row for index_col, index_row in itertools.product(\n",
        "                      [str(x) for x in range(data.shape[0])], \n",
        "                      [str(x) for x in data.columns])]\n",
        "              )\n",
        "      return unlisted_df\n",
        "      \n",
        "    def loop_over_monte_carlo_samples(self):\n",
        "      i_size = self.sample_size\n",
        "      j_size = len(self.target_features)\n",
        "      data_sample = []\n",
        "\n",
        "      for i in range(i_size):\n",
        "        reference_index = np.random.choice(np.arange(0, self.n_features ), size=1, replace=False)\n",
        "        feature_indices_random = np.random.choice(np.arange(0, self.n_features), size=self.n_features, replace=False)\n",
        "        # r индексация стартует с 1 а питон с 0 поэтому нам нужно вычиать 1 или ставить по верхней границе индексы в зависимости от функции вызова\n",
        "        feature_names_random = self.explain.columns[feature_indices_random].values\n",
        "        reference_instance = self.reference.iloc[reference_index, feature_indices_random]\n",
        "        #feature_indices_random это вектор индексов\n",
        "        explain_instances = self.explain.iloc[:, feature_indices_random]\n",
        "        data_sample_feature = []\n",
        "        for j in range(j_size):\n",
        "          target_feature_index =  self.explain.columns.get_loc(self.target_features[j])\n",
        "          target_feature_index_shuffled = list(self.explain.columns.values[feature_indices_random]).index(self.target_features[j])\n",
        "          #if True:\n",
        "          #  print(target_feature_index)\n",
        "          # target_feature_index = (self.explain.columns == self.target_features[j])\n",
        "          # target_feature_index_shuffled = (self.explain.columns[feature_indices_random] == self.target_features[j])\n",
        "          \n",
        "          if self.target_features[j] in self.nodes:\n",
        "            #unlist как я понял, вытягивает все данные в один длинный вектор, присваивает индексы как название колонки + название строки\n",
        "            #предположу, что each_node_causes это pd.DataFrame()\n",
        "            target_feature_causes_these_features =  [self.target_features[j]] + self.each_node_causes.get(self.target_features[j], []) \n",
        "                \n",
        "            target_feature_is_caused_by =  [self.target_features[j]] + self.each_node_is_an_effect_from.get(self.target_features[j], []) \n",
        "            target_index = target_feature_index_shuffled\n",
        "            #отмечаем те значения feature_names_random которые равны последнему значению \n",
        "            #target_feature_is_caused_by. target_feature_is_caused_by вроде как вектор\n",
        "            #вернуться должно число. Если вдруг окажется, что датафрейм, -1 элемент будет строка, \n",
        "            #надо заменить на индексацию на iloc, == на .isin\n",
        "            causes_indices = np.where(feature_names_random == target_feature_is_caused_by[-1])[0].item()\n",
        "            effects_indices = np.where(feature_names_random == target_feature_causes_these_features[-1])[0].item()\n",
        "            sample_indices = feature_indices_random[~np.isin(feature_indices_random, \n",
        "                np.concatenate([[target_index], [causes_indices], [effects_indices]]))]\n",
        "            #c() вроде как склеивает вектор(ы) и переменные\n",
        "            sample_real_indices = sample_indices[sample_indices < target_index]  # Not in causal diagram, feature data from 'explain'.\n",
        "            sample_fake_indices = sample_indices[sample_indices > target_index]  # Not in causal diagram, feature data from 'reference'.\n",
        "\n",
        "            feature_indices_real_causes_real_effects = np.concatenate([sample_real_indices, [causes_indices], [effects_indices], [target_index], sample_fake_indices])\n",
        "            feature_indices_real_causes_fake_effects = np.concatenate([sample_real_indices, [causes_indices], [target_index], [effects_indices], sample_fake_indices])\n",
        "            feature_indices_fake_causes_real_effects = np.concatenate([sample_real_indices, [effects_indices], [target_index], [causes_indices], sample_fake_indices])\n",
        "            feature_indices_fake_causes_fake_effects = np.concatenate([sample_real_indices, [target_index], [causes_indices], [effects_indices], sample_fake_indices])\n",
        "          \n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            explain_instance_real_target = explain_instances.copy()\n",
        "\n",
        "            # Only create a Frankenstein instance if the target is not the last feature and there is actually\n",
        "            # one or more features to the right of the target to replace with the reference.\n",
        "            if (target_feature_index_shuffled < self.n_features):\n",
        "              #x = reference_instance.iloc[:, target_feature_index_shuffled: ]\n",
        "              explain_instance_real_target.iloc[:, target_feature_index_shuffled+1: ] =\\\n",
        "                 pd.concat([reference_instance.iloc[:, target_feature_index_shuffled+1: ]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              \n",
        "            # These instances are otherwise the same as the Frankenstein instance created above with the\n",
        "            # exception that the target feature is now replaced with the target feature in the random reference\n",
        "            # instance. The difference in model predictions between these two Frankenstein instances is\n",
        "            # what gives us the stochastic Shapley value approximation.\n",
        "            explain_instance_fake_target = explain_instance_real_target.copy()\n",
        "            \n",
        "            # ОНИ ПОЧЕМУ ТО ВЫШЛИ ОДИНАКОВЫЕ, ЭТО ОК?\n",
        "            explain_instance_fake_target.iloc[:, [target_feature_index_shuffled]] =\\\n",
        "               pd.concat([reference_instance.iloc[:, [target_feature_index_shuffled]]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "          \n",
        "          else:\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              target_index_temp = (explain_instance_real_causes_fake_effects_real_target.columns.values == self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_real_causes_fake_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]\n",
        "\n",
        "              explain_instance_real_causes_fake_effects_fake_target = explain_instance_real_causes_fake_effects_real_target\n",
        "              explain_instance_real_causes_fake_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = (explain_instance_fake_causes_real_effects_real_target_cause.columns.values == self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_fake_causes_real_effects[:, target_index_temp + 1: self.n_features]\n",
        "              \n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause = explain_instance_fake_causes_real_effects_real_target_cause\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target_effect.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if (target_index_temp < self.n_features):\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]\n",
        "              \n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect = explain_instance_real_causes_fake_effects_real_target_effect\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = (explain_instance_fake_causes_real_effects_real_target.columns.values == self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features + 1]\n",
        "\n",
        "              explain_instance_fake_causes_real_effects_fake_target = explain_instance_fake_causes_real_effects_real_target\n",
        "              explain_instance_fake_causes_real_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]\n",
        "\n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            #магическим образом две нижеследующие строчки возвращают датафрейм к старому виду\n",
        "            explain_instance_real_target = explain_instance_real_target.loc[:, self.explain.columns]\n",
        "            explain_instance_fake_target = explain_instance_fake_target.loc[:, self.explain.columns]\n",
        "            data_explain_instance = pd.concat([explain_instance_real_target, explain_instance_fake_target], axis=0).reset_index(drop=True)#, ignore_index=True)\n",
        "            #вот тут не совсем понятно, индекс это число или строка, индексы в data_explain_instance это числа или строки? в любом случае, при запуске можно починить\n",
        "            data_explain_instance['index'] = np.tile(np.arange(0, self.explain.shape[0]), 2) \n",
        "            data_explain_instance['feature_group'] = np.repeat(['real_target', 'fake_target'], repeats=self.explain.shape[0])\n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 0\n",
        "            data_explain_instance['causal_type'] = None\n",
        "\n",
        "          else:\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause], axis=0\n",
        "              ).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",\n",
        "                                                          \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_a_cause\"\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",\n",
        "                                                          \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_an_effect\"\n",
        "\n",
        "            if (self.target_features[j] in self.causal_nodes) and (self.target_features[j] in self.effect_nodes):\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause,\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 8)  # Eight Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\n",
        "                \"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",  # Target is a causal node.\n",
        "                \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\",  # Target is a causal node.\n",
        "                \"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",  # Target is an effect node.\n",
        "                \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"  # Target is an effect node.\n",
        "                ]),\n",
        "              self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = np.tile(pd.Series([\n",
        "                \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\",\n",
        "                \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\"]\n",
        "              ),\n",
        "              self.explain.shape[0])\n",
        "            \n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 1\n",
        "\n",
        "          data_explain_instance['sample'] = i\n",
        "          data_sample_feature.append(data_explain_instance)\n",
        "\n",
        "        data_sample.append(data_sample_feature)\n",
        "\n",
        "      data_sample = pd.concat([pd.concat(data_sample_i, axis=0) for data_sample_i in data_sample], axis=0)\n",
        "      return data_sample\n",
        "\n",
        "    def predict_shapFlex(self, data_predict):\n",
        "      '''есть self.reference, self.model, self.predict_function, self.n_features, self.causal, self.causal_weights'''\n",
        "      data_model = data_predict.iloc[:, :self.n_features]\n",
        "      data_meta = data_predict.iloc[:, self.n_features:]\n",
        "      data_predicted = pd.DataFrame(predict_function(self.model, data_model), index=data_model.index)\n",
        "      data_predicted = pd.concat([data_meta, data_predicted], axis=1)\n",
        "      #мб придется править, в зависимости от формата входных данных (вектор-строка/-столбец), пока результат по всем измерениям, скаляр\n",
        "      intercept = predict_function(self.model, self.reference).mean(skipna=True)\n",
        "      #вмест data.shape[1] взял -1\n",
        "      #костыль, не понимаю, что тут должно быть пока\n",
        "      user_fun_y_pred_name = data_predicted.columns[-1]\n",
        "      #тут нюанс: у них перед вэлью !! стоит, что значит значение которое за ними следует, это не значение, а expression, что бы это \n",
        "      # ни значило, соответсвенно, может беда быть\n",
        "      #data_predicted = pd.concat([\n",
        "      #  data_predicted.drop('feature_group', axis=1), \n",
        "      #  data_predicted.reset_index().pivot_table(index='index', columns=[ 'feature_group'], values=user_fun_y_pred_name)\n",
        "      #  ], axis=1)\n",
        "      data_predicted = data_predicted.reset_index().pivot_table(\n",
        "        index=set(data_predicted.columns) - set(['index', 'feature_group', user_fun_y_pred_name]),\n",
        "        columns=['feature_group'],\n",
        "        values=user_fun_y_pred_name\n",
        "      )\n",
        "      data_non_causal = data_predicted.loc[data_predicted['causal']==0]\n",
        "      data_non_causal['shap_effect'] = data_non_causal['real_target'] - data_non_causal['fake_target']\n",
        "      data_causal = data_predicted.loc[data_predicted['causal']==1]\n",
        "\n",
        "      if isinstance(self.causal, pd.core.frame.DataFrame):\n",
        "        pass\n",
        "\n",
        "      data_predicted = pd.concat([data_causal, data_non_causal], ignore_index=True, axis=0)\n",
        "      data_predicted = data_predicted.loc[:, ['index', 'sample', 'feature_name', 'shap_effect']]\n",
        "\n",
        "      data_predicted = data_predicted.reset_index().dropna(axis=0).groupby(['index', 'feature_name']).agg({'shap_effect': [np.std, np.mean]})\n",
        "      data_predicted[('shap_effect', 'intercept')] = intercept[0]\n",
        "\n",
        "      return data_predicted\n",
        "\n",
        "    def forward(self):\n",
        "      data_predict = self.loop_over_monte_carlo_samples()\n",
        "      data_predicted = self.predict_shapFlex(data_predict)\n",
        "      return data_predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('https://kolodezev.ru/download/data_adult.csv', index_col=0)\n",
        "outcome_name = 'income'\n",
        "outcome_col = pd.Series(data.columns)[data.columns==outcome_name].index[0]\n",
        "X, y = data.drop(outcome_name, axis=1), data[outcome_name].values\n",
        "cat_features = [inx for inx, value in zip(X.dtypes.index, X.dtypes) if value =='object']\n",
        "model = CatBoostClassifier()\n",
        "model.fit(X, y, cat_features=cat_features, verbose=False)\n",
        "def predict_function(model, data):\n",
        "  #pd.DataFrame(model.predict_proba(X)).loc[:, 0][9] если запустить будет результат 0.98, что соответствует\n",
        "  #выводу для 9 номера который равен 0.98, неважно какой алгоритм, такая высокая степень уверенности\n",
        "  #позволяет идентифицировать выводимую колонку однозначно\n",
        "  return pd.DataFrame(model.predict_proba(data)[:, [0]])\n",
        "\n",
        "\n",
        "explain, reference = data.iloc[:350, :data.shape[1]-1], data.iloc[:, :data.shape[1]-1]\n",
        "sample_size = 60\n",
        "target_features = pd.Series([\"marital_status\", \"education\", \"relationship\",  \"native_country\",\n",
        "                     \"age\", \"sex\", \"race\", \"hours_per_week\"])\n",
        "causal = pd.DataFrame(\n",
        "  dict(cause=pd.Series([\"age\", \"sex\", \"race\", \"native_country\",\n",
        "              \"age\", \"sex\", \"race\", \"native_country\", \"age\",\n",
        "              \"sex\", \"race\", \"native_country\"]),\n",
        "  effect = pd.Series(np.concatenate([np.tile(\"marital_status\", 4), np.tile(\"education\", 4), np.tile(\"relationship\", 4)])))\n",
        ")\n",
        "exmpl_of_test = shapFlex_plus(explain,  model, predict_function, target_features=pd.Series([\"marital_status\", \"education\", \"relationship\", \"native_country\",\n",
        "\"age\", \"sex\", \"race\", \"hours_per_week\"]), causal=causal, causal_weights = [0.5 for x in range(len(causal))])\n",
        "data_predict = exmpl_of_test.loop_over_monte_carlo_samples()\n",
        "data_predicted = exmpl_of_test.predict_shapFlex(data_predict)\n",
        "print(data_predicted)"
      ],
      "metadata": {
        "id": "dn842KXq6EQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25/03/2022\n",
        "# 134 строка удалили +1 после :\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import igraph\n",
        "import itertools\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "class shapFlex_plus:\n",
        "    def __init__(self, explain,  model, predict_function, reference = None, target_features = None, \\\n",
        "                     causal = None, causal_weights = None, sample_size = None, use_future = None):\n",
        "        self.explain = explain\n",
        "        self.reference = reference if reference else explain\n",
        "        self.model = model\n",
        "        self.predict_function = predict_function\n",
        "        self.target_features = target_features if isinstance(target_features, pd.core.series.Series) else explain.columns.tolist()\n",
        "        self.causal = causal #if causal else None\n",
        "        self.causal_weights = causal_weights #if causal_weights else None\n",
        "        self.sample_size = sample_size if sample_size else 60\n",
        "        self.use_future = use_future if isinstance(target_features, pd.core.series.Series) else False\n",
        "        \n",
        "        self.n_features = self.explain.shape[1]\n",
        "        self.n_instances = self.reference.shape[0]\n",
        "\n",
        "        self.causal_graph = igraph.Graph.DataFrame(self.causal, directed=True) if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v for v in self.causal_graph.vs] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.each_node_causes = {v['name']: [succ['name'] for succ in v.successors()] for v in self.nodes if v.successors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# надо уточнить, мб здесь не только \"прямые\" successors и predecessors ищутся \n",
        "        self.each_node_is_an_effect_from = {v['name']: [pred['name'] for pred in v.predecessors()] for v in self.nodes if v.predecessors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# но и вообще все\n",
        "        # имена, кажется, уже прописаны автоматически\n",
        "        self.causal_nodes = [v for v in self.each_node_causes.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.effect_nodes = [v for v in self.each_node_is_an_effect_from.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v['name'] for v in self.nodes] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "\n",
        "    @staticmethod\n",
        "    def unlist_df(data):\n",
        "      unlisted_df = pd.Series(\n",
        "                  data,\n",
        "                  index=[\n",
        "                  index_col + index_row for index_col, index_row in itertools.product(\n",
        "                      [str(x) for x in range(data.shape[0])], \n",
        "                      [str(x) for x in data.columns])]\n",
        "              )\n",
        "      return unlisted_df\n",
        "      \n",
        "    def loop_over_monte_carlo_samples(self):\n",
        "      i_size = self.sample_size\n",
        "      j_size = len(self.target_features)\n",
        "      data_sample = []\n",
        "\n",
        "      for i in range(i_size):\n",
        "        reference_index = np.random.choice(np.arange(0, self.n_features ), size=1, replace=False)\n",
        "        feature_indices_random = np.random.choice(np.arange(0, self.n_features), size=self.n_features, replace=False)\n",
        "        # r индексация стартует с 1 а питон с 0 поэтому нам нужно вычиать 1 или ставить по верхней границе индексы в зависимости от функции вызова\n",
        "        feature_names_random = self.explain.columns[feature_indices_random].values\n",
        "        reference_instance = self.reference.iloc[reference_index, feature_indices_random]\n",
        "        #feature_indices_random это вектор индексов\n",
        "        explain_instances = self.explain.iloc[:, feature_indices_random]\n",
        "        data_sample_feature = []\n",
        "        for j in range(j_size):\n",
        "          target_feature_index =  self.explain.columns.get_loc(self.target_features[j])\n",
        "          target_feature_index_shuffled = list(self.explain.columns.values[feature_indices_random]).index(self.target_features[j])\n",
        "          #if True:\n",
        "          #  print(target_feature_index)\n",
        "          # target_feature_index = (self.explain.columns == self.target_features[j])\n",
        "          # target_feature_index_shuffled = (self.explain.columns[feature_indices_random] == self.target_features[j])\n",
        "          \n",
        "          if self.target_features[j] in self.nodes:\n",
        "            #unlist как я понял, вытягивает все данные в один длинный вектор, присваивает индексы как название колонки + название строки\n",
        "            #предположу, что each_node_causes это pd.DataFrame()\n",
        "            target_feature_causes_these_features =  [self.target_features[j]] + self.each_node_causes.get(self.target_features[j], []) \n",
        "                \n",
        "            target_feature_is_caused_by =  [self.target_features[j]] + self.each_node_is_an_effect_from.get(self.target_features[j], []) \n",
        "            target_index = target_feature_index_shuffled\n",
        "            #отмечаем те значения feature_names_random которые равны последнему значению \n",
        "            #target_feature_is_caused_by. target_feature_is_caused_by вроде как вектор\n",
        "            #вернуться должно число. Если вдруг окажется, что датафрейм, -1 элемент будет строка, \n",
        "            #надо заменить на индексацию на iloc, == на .isin\n",
        "            causes_indices = np.where(feature_names_random == target_feature_is_caused_by[1:])[0]\n",
        "            effects_indices = np.where(feature_names_random == target_feature_causes_these_features[1:])[0]\n",
        "            sample_indices = feature_indices_random[~np.isin(feature_indices_random, \n",
        "                np.concatenate([[target_index], causes_indices, effects_indices]))]\n",
        "            #c() вроде как склеивает вектор(ы) и переменные\n",
        "            sample_real_indices = sample_indices[sample_indices < target_index]  # Not in causal diagram, feature data from 'explain'.\n",
        "            sample_fake_indices = sample_indices[sample_indices > target_index]  # Not in causal diagram, feature data from 'reference'.\n",
        "\n",
        "            feature_indices_real_causes_real_effects = np.concatenate([sample_real_indices, causes_indices, effects_indices, [target_index], sample_fake_indices])\n",
        "            feature_indices_real_causes_fake_effects = np.concatenate([sample_real_indices, causes_indices, [target_index], effects_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_real_effects = np.concatenate([sample_real_indices, effects_indices, [target_index], causes_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_fake_effects = np.concatenate([sample_real_indices, [target_index], causes_indices, effects_indices, sample_fake_indices])\n",
        "          \n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            explain_instance_real_target = explain_instances.copy()\n",
        "\n",
        "            # Only create a Frankenstein instance if the target is not the last feature and there is actually\n",
        "            # one or more features to the right of the target to replace with the reference.\n",
        "            if (target_feature_index_shuffled < self.n_features):\n",
        "              #x = reference_instance.iloc[:, target_feature_index_shuffled: ]\n",
        "              explain_instance_real_target.iloc[:, target_feature_index_shuffled+1: ] =\\\n",
        "                 pd.concat([reference_instance.iloc[:, target_feature_index_shuffled+1: ]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              \n",
        "            # These instances are otherwise the same as the Frankenstein instance created above with the\n",
        "            # exception that the target feature is now replaced with the target feature in the random reference\n",
        "            # instance. The difference in model predictions between these two Frankenstein instances is\n",
        "            # what gives us the stochastic Shapley value approximation.\n",
        "            explain_instance_fake_target = explain_instance_real_target.copy()\n",
        "            \n",
        "            # ОНИ ПОЧЕМУ ТО ВЫШЛИ ОДИНАКОВЫЕ, ЭТО ОК?\n",
        "            explain_instance_fake_target.iloc[:, [target_feature_index_shuffled]] =\\\n",
        "               pd.concat([reference_instance.iloc[:, [target_feature_index_shuffled]]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "          \n",
        "          else:\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              \n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_real_causes_fake_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "              explain_instance_real_causes_fake_effects_fake_target = explain_instance_real_causes_fake_effects_real_target\n",
        "              explain_instance_real_causes_fake_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_fake_causes_real_effects_real_target_cause.columns.get_loc(self.target_features[j])\n",
        "              \n",
        "\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause.iloc[:, target_index_temp + 1:] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects[:, target_index_temp + 1:]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause = explain_instance_fake_causes_real_effects_real_target_cause\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target_effect.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if (target_index_temp < self.n_features):\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect = explain_instance_real_causes_fake_effects_real_target_effect\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              pd.concat([reference_instance.iloc[:, feature_indices_fake_causes_real_effects]]*self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "              explain_instance_fake_causes_real_effects_real_target = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_fake_causes_real_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features + 1]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "              explain_instance_fake_causes_real_effects_fake_target = explain_instance_fake_causes_real_effects_real_target\n",
        "              explain_instance_fake_causes_real_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]]*self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            #магическим образом две нижеследующие строчки возвращают датафрейм к старому виду\n",
        "            explain_instance_real_target = explain_instance_real_target.loc[:, self.explain.columns]\n",
        "            explain_instance_fake_target = explain_instance_fake_target.loc[:, self.explain.columns]\n",
        "            data_explain_instance = pd.concat([explain_instance_real_target, explain_instance_fake_target], axis=0).reset_index(drop=True)#, ignore_index=True)\n",
        "            #вот тут не совсем понятно, индекс это число или строка, индексы в data_explain_instance это числа или строки? в любом случае, при запуске можно починить\n",
        "            data_explain_instance['index'] = np.tile(np.arange(0, self.explain.shape[0]), 2) \n",
        "            data_explain_instance['feature_group'] = np.repeat(['real_target', 'fake_target'], repeats=self.explain.shape[0])\n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 0\n",
        "            data_explain_instance['causal_type'] = None\n",
        "\n",
        "          else:\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause], axis=0\n",
        "              ).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",\n",
        "                                                          \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_a_cause\"\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",\n",
        "                                                          \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_an_effect\"\n",
        "\n",
        "            if (self.target_features[j] in self.causal_nodes) and (self.target_features[j] in self.effect_nodes):\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause,\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 8)  # Eight Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\n",
        "                \"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",  # Target is a causal node.\n",
        "                \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\",  # Target is a causal node.\n",
        "                \"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",  # Target is an effect node.\n",
        "                \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"  # Target is an effect node.\n",
        "                ]),\n",
        "              self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = np.tile(pd.Series([\n",
        "                \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\",\n",
        "                \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\"]\n",
        "              ),\n",
        "              self.explain.shape[0])\n",
        "            \n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 1\n",
        "\n",
        "          data_explain_instance['sample'] = i\n",
        "          data_sample_feature.append(data_explain_instance)\n",
        "\n",
        "        data_sample.append(data_sample_feature)\n",
        "\n",
        "      data_sample = pd.concat([pd.concat(data_sample_i, axis=0) for data_sample_i in data_sample], axis=0)\n",
        "      return data_sample\n",
        "\n",
        "    def predict_shapFlex(self, data_predict):\n",
        "      '''есть self.reference, self.model, self.predict_function, self.n_features, self.causal, self.causal_weights'''\n",
        "      data_model = data_predict.iloc[:, :self.n_features]\n",
        "      data_meta = data_predict.iloc[:, self.n_features:]\n",
        "      data_predicted = pd.DataFrame(predict_function(self.model, data_model), index=data_model.index)\n",
        "      data_predicted = pd.concat([data_meta, data_predicted], axis=1)\n",
        "      #мб придется править, в зависимости от формата входных данных (вектор-строка/-столбец), пока результат по всем измерениям, скаляр\n",
        "      intercept = predict_function(self.model, self.reference).mean(skipna=True)\n",
        "      #вмест data.shape[1] взял -1\n",
        "      #костыль, не понимаю, что тут должно быть пока\n",
        "      user_fun_y_pred_name = data_predicted.columns[-1]\n",
        "      #тут нюанс: у них перед вэлью !! стоит, что значит значение которое за ними следует, это не значение, а expression, что бы это \n",
        "      # ни значило, соответсвенно, может беда быть\n",
        "      #data_predicted = pd.concat([\n",
        "      #  data_predicted.drop('feature_group', axis=1), \n",
        "      #  data_predicted.reset_index().pivot_table(index='index', columns=[ 'feature_group'], values=user_fun_y_pred_name)\n",
        "      #  ], axis=1)\n",
        "      data_predicted = data_predicted.reset_index().pivot_table(\n",
        "        index=set(data_predicted.columns) - set(['index', 'feature_group', user_fun_y_pred_name]),\n",
        "        columns=['feature_group'],\n",
        "        values=user_fun_y_pred_name\n",
        "      )\n",
        "      data_non_causal = data_predicted.loc[data_predicted['causal']==0]\n",
        "      data_non_causal['shap_effect'] = data_non_causal['real_target'] - data_non_causal['fake_target']\n",
        "      data_causal = data_predicted.loc[data_predicted['causal']==1]\n",
        "\n",
        "      if isinstance(self.causal, pd.core.frame.DataFrame):\n",
        "        pass\n",
        "\n",
        "      data_predicted = pd.concat([data_causal, data_non_causal], ignore_index=True, axis=0)\n",
        "      data_predicted = data_predicted.loc[:, ['index', 'sample', 'feature_name', 'shap_effect']]\n",
        "\n",
        "      data_predicted = data_predicted.reset_index().dropna(axis=0).groupby(['index', 'feature_name']).agg({'shap_effect': [np.std, np.mean]})\n",
        "      data_predicted[('shap_effect', 'intercept')] = intercept[0]\n",
        "\n",
        "      return data_predicted\n",
        "\n",
        "    def forward(self):\n",
        "      data_predict = self.loop_over_monte_carlo_samples()\n",
        "      data_predicted = self.predict_shapFlex(data_predict)\n",
        "      return data_predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('https://kolodezev.ru/download/data_adult.csv', index_col=0)\n",
        "outcome_name = 'income'\n",
        "outcome_col = pd.Series(data.columns)[data.columns==outcome_name].index[0]\n",
        "X, y = data.drop(outcome_name, axis=1), data[outcome_name].values\n",
        "cat_features = [inx for inx, value in zip(X.dtypes.index, X.dtypes) if value =='object']\n",
        "model = CatBoostClassifier()\n",
        "model.fit(X, y, cat_features=cat_features, verbose=False)\n",
        "def predict_function(model, data):\n",
        "  #pd.DataFrame(model.predict_proba(X)).loc[:, 0][9] если запустить будет результат 0.98, что соответствует\n",
        "  #выводу для 9 номера который равен 0.98, неважно какой алгоритм, такая высокая степень уверенности\n",
        "  #позволяет идентифицировать выводимую колонку однозначно\n",
        "  return pd.DataFrame(model.predict_proba(data)[:, [0]])\n",
        "\n",
        "\n",
        "explain, reference = data.iloc[:350, :data.shape[1]-1], data.iloc[:, :data.shape[1]-1]\n",
        "sample_size = 60\n",
        "target_features = pd.Series([\"marital_status\", \"education\", \"relationship\",  \"native_country\",\n",
        "                     \"age\", \"sex\", \"race\", \"hours_per_week\"])\n",
        "causal = pd.DataFrame(\n",
        "  dict(cause=pd.Series([\"age\", \"sex\", \"race\", \"native_country\",\n",
        "              \"age\", \"sex\", \"race\", \"native_country\", \"age\",\n",
        "              \"sex\", \"race\", \"native_country\"]),\n",
        "  effect = pd.Series(np.concatenate([np.tile(\"marital_status\", 4), np.tile(\"education\", 4), np.tile(\"relationship\", 4)])))\n",
        ")\n",
        "exmpl_of_test = shapFlex_plus(explain,  model, predict_function, target_features=pd.Series([\"marital_status\", \"education\", \"relationship\", \"native_country\",\n",
        "\"age\", \"sex\", \"race\", \"hours_per_week\"]), causal=causal, causal_weights = [0.5 for x in range(len(causal))])\n",
        "data_predict = exmpl_of_test.loop_over_monte_carlo_samples()\n",
        "data_predicted = exmpl_of_test.predict_shapFlex(data_predict)\n",
        "print(data_predicted)"
      ],
      "metadata": {
        "id": "lWReJ5jiTrAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#28.03\n",
        "#падает уже в предикт шапфлекс потому что не реализован causal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import igraph\n",
        "import itertools\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "class shapFlex_plus:\n",
        "    def __init__(self, explain,  model, predict_function, reference = None, target_features = None, \\\n",
        "                     causal = None, causal_weights = None, sample_size = None, use_future = None):\n",
        "        self.explain = explain\n",
        "        self.reference = reference if reference else explain\n",
        "        self.model = model\n",
        "        self.predict_function = predict_function\n",
        "        self.target_features = target_features if isinstance(target_features, pd.core.series.Series) else explain.columns.tolist()\n",
        "        self.causal = causal #if causal else None\n",
        "        self.causal_weights = causal_weights #if causal_weights else None\n",
        "        self.sample_size = sample_size if sample_size else 60\n",
        "        self.use_future = use_future if isinstance(target_features, pd.core.series.Series) else False\n",
        "        \n",
        "        self.n_features = self.explain.shape[1]\n",
        "        self.n_instances = self.reference.shape[0]\n",
        "\n",
        "        self.causal_graph = igraph.Graph.DataFrame(self.causal, directed=True) if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v for v in self.causal_graph.vs] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.each_node_causes = {v['name']: [succ['name'] for succ in v.successors()] for v in self.nodes if v.successors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# надо уточнить, мб здесь не только \"прямые\" successors и predecessors ищутся \n",
        "        self.each_node_is_an_effect_from = {v['name']: [pred['name'] for pred in v.predecessors()] for v in self.nodes if v.predecessors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# но и вообще все\n",
        "        # имена, кажется, уже прописаны автоматически\n",
        "        self.causal_nodes = [v for v in self.each_node_causes.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.effect_nodes = [v for v in self.each_node_is_an_effect_from.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v['name'] for v in self.nodes] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "\n",
        "    @staticmethod\n",
        "    def unlist_df(data):\n",
        "      unlisted_df = pd.Series(\n",
        "                  data,\n",
        "                  index=[\n",
        "                  index_col + index_row for index_col, index_row in itertools.product(\n",
        "                      [str(x) for x in range(data.shape[0])], \n",
        "                      [str(x) for x in data.columns])]\n",
        "              )\n",
        "      return unlisted_df\n",
        "      \n",
        "    def loop_over_monte_carlo_samples(self):\n",
        "      i_size = self.sample_size\n",
        "      j_size = len(self.target_features)\n",
        "      data_sample = []\n",
        "\n",
        "      for i in range(i_size):\n",
        "        reference_index = np.random.choice(np.arange(0, self.n_features ), size=1, replace=False)\n",
        "        feature_indices_random = np.random.choice(np.arange(0, self.n_features), size=self.n_features, replace=False)\n",
        "        # r индексация стартует с 1 а питон с 0 поэтому нам нужно вычиать 1 или ставить по верхней границе индексы в зависимости от функции вызова\n",
        "        feature_names_random = self.explain.columns[feature_indices_random].values\n",
        "        reference_instance = self.reference.iloc[reference_index, feature_indices_random]\n",
        "        #feature_indices_random это вектор индексов\n",
        "        explain_instances = self.explain.iloc[:, feature_indices_random]\n",
        "        data_sample_feature = []\n",
        "        for j in range(j_size):\n",
        "          target_feature_index =  self.explain.columns.get_loc(self.target_features[j])\n",
        "          target_feature_index_shuffled = list(self.explain.columns.values[feature_indices_random]).index(self.target_features[j])\n",
        "          #if True:\n",
        "          #  print(target_feature_index)\n",
        "          # target_feature_index = (self.explain.columns == self.target_features[j])\n",
        "          # target_feature_index_shuffled = (self.explain.columns[feature_indices_random] == self.target_features[j])\n",
        "          \n",
        "          if self.target_features[j] in self.nodes:\n",
        "            #unlist как я понял, вытягивает все данные в один длинный вектор, присваивает индексы как название колонки + название строки\n",
        "            #предположу, что each_node_causes это pd.DataFrame()\n",
        "            target_feature_causes_these_features =  [self.target_features[j]] + self.each_node_causes.get(self.target_features[j], []) \n",
        "            target_feature_is_caused_by =  [self.target_features[j]] + self.each_node_is_an_effect_from.get(self.target_features[j], []) \n",
        "            target_index = target_feature_index_shuffled\n",
        "            #отмечаем те значения feature_names_random которые равны последнему значению \n",
        "            #target_feature_is_caused_by. target_feature_is_caused_by вроде как вектор\n",
        "            #вернуться должно число. Если вдруг окажется, что датафрейм, -1 элемент будет строка, \n",
        "            #надо заменить на индексацию на iloc, == на .isin\n",
        "            causes_indices = np.where(np.in1d(feature_names_random, target_feature_is_caused_by[1:]))[0]\n",
        "            effects_indices  = np.where(np.in1d(feature_names_random, target_feature_causes_these_features[1:]))[0]\n",
        "            sample_indices = feature_indices_random[~np.isin(feature_indices_random, \n",
        "                np.concatenate([[target_index], causes_indices, effects_indices]))]\n",
        "            #c() вроде как склеивает вектор(ы) и переменные\n",
        "            sample_real_indices = sample_indices[sample_indices < target_index]  # Not in causal diagram, feature data from 'explain'.\n",
        "            sample_fake_indices = sample_indices[sample_indices > target_index]  # Not in causal diagram, feature data from 'reference'.\n",
        "\n",
        "            feature_indices_real_causes_real_effects = np.concatenate([sample_real_indices, causes_indices, effects_indices, [target_index], sample_fake_indices])\n",
        "            feature_indices_real_causes_fake_effects = np.concatenate([sample_real_indices, causes_indices, [target_index], effects_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_real_effects = np.concatenate([sample_real_indices, effects_indices, [target_index], causes_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_fake_effects = np.concatenate([sample_real_indices, [target_index], causes_indices, effects_indices, sample_fake_indices])\n",
        "          \n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            explain_instance_real_target = explain_instances.copy()\n",
        "\n",
        "            # Only create a Frankenstein instance if the target is not the last feature and there is actually\n",
        "            # one or more features to the right of the target to replace with the reference.\n",
        "            if (target_feature_index_shuffled < self.n_features):\n",
        "              #x = reference_instance.iloc[:, target_feature_index_shuffled: ]\n",
        "              explain_instance_real_target.iloc[:, target_feature_index_shuffled+1: ] =\\\n",
        "                 pd.concat([reference_instance.iloc[:, target_feature_index_shuffled+1: ]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              \n",
        "            # These instances are otherwise the same as the Frankenstein instance created above with the\n",
        "            # exception that the target feature is now replaced with the target feature in the random reference\n",
        "            # instance. The difference in model predictions between these two Frankenstein instances is\n",
        "            # what gives us the stochastic Shapley value approximation.\n",
        "            explain_instance_fake_target = explain_instance_real_target.copy()\n",
        "            \n",
        "            # ОНИ ПОЧЕМУ ТО ВЫШЛИ ОДИНАКОВЫЕ, ЭТО ОК?\n",
        "            explain_instance_fake_target.iloc[:, [target_feature_index_shuffled]] =\\\n",
        "               pd.concat([reference_instance.iloc[:, [target_feature_index_shuffled]]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "          \n",
        "          else:\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_real_causes_fake_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "                \n",
        "\n",
        "              explain_instance_real_causes_fake_effects_fake_target = explain_instance_real_causes_fake_effects_real_target\n",
        "              explain_instance_real_causes_fake_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features+1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              \n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause = explain_instance_fake_causes_real_effects_real_target_cause\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target_effect.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if (target_index_temp < self.n_features):\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              \n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect = explain_instance_real_causes_fake_effects_real_target_effect\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.iloc[:, target_index_temp] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_fake_causes_real_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "                \n",
        "\n",
        "              explain_instance_fake_causes_real_effects_fake_target = explain_instance_fake_causes_real_effects_real_target\n",
        "              explain_instance_fake_causes_real_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "\n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            #магическим образом две нижеследующие строчки возвращают датафрейм к старому виду\n",
        "            explain_instance_real_target = explain_instance_real_target.loc[:, self.explain.columns]\n",
        "            explain_instance_fake_target = explain_instance_fake_target.loc[:, self.explain.columns]\n",
        "            data_explain_instance = pd.concat([explain_instance_real_target, explain_instance_fake_target], axis=0).reset_index(drop=True)#, ignore_index=True)\n",
        "            #вот тут не совсем понятно, индекс это число или строка, индексы в data_explain_instance это числа или строки? в любом случае, при запуске можно починить\n",
        "            data_explain_instance['index'] = np.tile(np.arange(0, self.explain.shape[0]), 2) \n",
        "            data_explain_instance['feature_group'] = np.repeat(['real_target', 'fake_target'], repeats=self.explain.shape[0])\n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 0\n",
        "            data_explain_instance['causal_type'] = None\n",
        "\n",
        "          else:\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause], axis=0\n",
        "              ).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",\n",
        "                                                          \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_a_cause\"\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",\n",
        "                                                          \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_an_effect\"\n",
        "\n",
        "            if (self.target_features[j] in self.causal_nodes) and (self.target_features[j] in self.effect_nodes):\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause,\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 8)  # Eight Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\n",
        "                \"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",  # Target is a causal node.\n",
        "                \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\",  # Target is a causal node.\n",
        "                \"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",  # Target is an effect node.\n",
        "                \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"  # Target is an effect node.\n",
        "                ]),\n",
        "              self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = np.tile(pd.Series([\n",
        "                \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\",\n",
        "                \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\"]\n",
        "              ),\n",
        "              self.explain.shape[0])\n",
        "            \n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 1\n",
        "\n",
        "          data_explain_instance['sample'] = i\n",
        "          data_sample_feature.append(data_explain_instance)\n",
        "\n",
        "        data_sample.append(data_sample_feature)\n",
        "\n",
        "      data_sample = pd.concat([pd.concat(data_sample_i, axis=0) for data_sample_i in data_sample], axis=0)\n",
        "      return data_sample\n",
        "\n",
        "    def predict_shapFlex(self, data_predict):\n",
        "      '''есть self.reference, self.model, self.predict_function, self.n_features, self.causal, self.causal_weights'''\n",
        "      data_model = data_predict.iloc[:, :self.n_features]\n",
        "      data_meta = data_predict.iloc[:, self.n_features:]\n",
        "      data_predicted = pd.DataFrame(predict_function(self.model, data_model), index=data_model.index)\n",
        "      data_predicted = pd.concat([data_meta, data_predicted], axis=1)\n",
        "      #мб придется править, в зависимости от формата входных данных (вектор-строка/-столбец), пока результат по всем измерениям, скаляр\n",
        "      intercept = predict_function(self.model, self.reference).mean(skipna=True)\n",
        "      #вмест data.shape[1] взял -1\n",
        "      #костыль, не понимаю, что тут должно быть пока\n",
        "      user_fun_y_pred_name = data_predicted.columns[-1]\n",
        "      #тут нюанс: у них перед вэлью !! стоит, что значит значение которое за ними следует, это не значение, а expression, что бы это \n",
        "      # ни значило, соответсвенно, может беда быть\n",
        "      #data_predicted = pd.concat([\n",
        "      #  data_predicted.drop('feature_group', axis=1), \n",
        "      #  data_predicted.reset_index().pivot_table(index='index', columns=[ 'feature_group'], values=user_fun_y_pred_name)\n",
        "      #  ], axis=1)\n",
        "      data_predicted = data_predicted.reset_index().pivot_table(\n",
        "        index=set(data_predicted.columns) - set(['index', 'feature_group', user_fun_y_pred_name]),\n",
        "        columns=['feature_group'],\n",
        "        values=user_fun_y_pred_name\n",
        "      )\n",
        "      data_non_causal = data_predicted.loc[data_predicted['causal']==0]\n",
        "      data_non_causal['shap_effect'] = data_non_causal['real_target'] - data_non_causal['fake_target']\n",
        "      data_causal = data_predicted.loc[data_predicted['causal']==1]\n",
        "\n",
        "      if isinstance(self.causal, pd.core.frame.DataFrame):\n",
        "        pass\n",
        "\n",
        "      data_predicted = pd.concat([data_causal, data_non_causal], ignore_index=True, axis=0)\n",
        "      data_predicted = data_predicted.loc[:, ['index', 'sample', 'feature_name', 'shap_effect']]\n",
        "\n",
        "      data_predicted = data_predicted.reset_index().dropna(axis=0).groupby(['index', 'feature_name']).agg({'shap_effect': [np.std, np.mean]})\n",
        "      data_predicted[('shap_effect', 'intercept')] = intercept[0]\n",
        "\n",
        "      return data_predicted\n",
        "\n",
        "    def forward(self):\n",
        "      data_predict = self.loop_over_monte_carlo_samples()\n",
        "      data_predicted = self.predict_shapFlex(data_predict)\n",
        "      return data_predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('https://kolodezev.ru/download/data_adult.csv', index_col=0)\n",
        "outcome_name = 'income'\n",
        "outcome_col = pd.Series(data.columns)[data.columns==outcome_name].index[0]\n",
        "X, y = data.drop(outcome_name, axis=1), data[outcome_name].values\n",
        "cat_features = [inx for inx, value in zip(X.dtypes.index, X.dtypes) if value =='object']\n",
        "model = CatBoostClassifier()\n",
        "model.fit(X, y, cat_features=cat_features, verbose=False)\n",
        "def predict_function(model, data):\n",
        "  #pd.DataFrame(model.predict_proba(X)).loc[:, 0][9] если запустить будет результат 0.98, что соответствует\n",
        "  #выводу для 9 номера который равен 0.98, неважно какой алгоритм, такая высокая степень уверенности\n",
        "  #позволяет идентифицировать выводимую колонку однозначно\n",
        "  return pd.DataFrame(model.predict_proba(data)[:, [0]])\n",
        "\n",
        "\n",
        "explain, reference = data.iloc[:350, :data.shape[1]-1], data.iloc[:, :data.shape[1]-1]\n",
        "sample_size = 60\n",
        "target_features = pd.Series([\"marital_status\", \"education\", \"relationship\",  \"native_country\",\n",
        "                     \"age\", \"sex\", \"race\", \"hours_per_week\"])\n",
        "causal = pd.DataFrame(\n",
        "  dict(cause=pd.Series([\"age\", \"sex\", \"race\", \"native_country\",\n",
        "              \"age\", \"sex\", \"race\", \"native_country\", \"age\",\n",
        "              \"sex\", \"race\", \"native_country\"]),\n",
        "  effect = pd.Series(np.concatenate([np.tile(\"marital_status\", 4), np.tile(\"education\", 4), np.tile(\"relationship\", 4)])))\n",
        ")\n",
        "exmpl_of_test = shapFlex_plus(explain,  model, predict_function, target_features=pd.Series([\"marital_status\", \"education\", \"relationship\", \"native_country\",\n",
        "\"age\", \"sex\", \"race\", \"hours_per_week\"]), causal=causal, causal_weights = [0.5 for x in range(len(causal))])\n",
        "data_predict = exmpl_of_test.loop_over_monte_carlo_samples()\n",
        "data_predicted = exmpl_of_test.predict_shapFlex(data_predict)\n",
        "print(data_predicted)"
      ],
      "metadata": {
        "id": "tT7i2rv0dFaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/data_predicted.csv\")\n",
        "df.info()\n",
        "#  data_predicted.pivot_table(\n",
        "#         index=set(data_predicted.columns) - set(['index', 'feature_group', user_fun_y_pred_name]),\n",
        "#         columns=['feature_group'],\n",
        "#         values=user_fun_y_pred_name\n",
        "#       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGycY1rbDH_c",
        "outputId": "15b9c5cc-ca0a-4016-e698-c5f6740076e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 630000 entries, 0 to 629999\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   Unnamed: 0       630000 non-null  int64  \n",
            " 1   index_in_sample  630000 non-null  int64  \n",
            " 2   feature_group    630000 non-null  object \n",
            " 3   causal_type      588000 non-null  object \n",
            " 4   feature_name     630000 non-null  object \n",
            " 5   causal           630000 non-null  int64  \n",
            " 6   sample           630000 non-null  int64  \n",
            " 7   0                630000 non-null  float64\n",
            "dtypes: float64(1), int64(4), object(3)\n",
            "memory usage: 38.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.fillna(0)\n",
        "df2 = df2.pivot_table(index =['causal', 'sample', 'causal_type', 'feature_name', 'index_in_sample'], columns=['feature_group'],values='0')\n",
        "df2.reset_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "UjKkxNVdEB_W",
        "outputId": "bdaa162d-b86f-4cd4-b55f-96bb6299ba54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature_group  causal  sample          causal_type    feature_name  \\\n",
              "0                   0       0                    0  hours_per_week   \n",
              "1                   0       0                    0  hours_per_week   \n",
              "2                   0       0                    0  hours_per_week   \n",
              "3                   0       0                    0  hours_per_week   \n",
              "4                   0       0                    0  hours_per_week   \n",
              "...               ...     ...                  ...             ...   \n",
              "167995              1      59  target_is_an_effect    relationship   \n",
              "167996              1      59  target_is_an_effect    relationship   \n",
              "167997              1      59  target_is_an_effect    relationship   \n",
              "167998              1      59  target_is_an_effect    relationship   \n",
              "167999              1      59  target_is_an_effect    relationship   \n",
              "\n",
              "feature_group  index_in_sample  fake_causes_real_effects_fake_target  \\\n",
              "0                            0                                   NaN   \n",
              "1                            1                                   NaN   \n",
              "2                            2                                   NaN   \n",
              "3                            3                                   NaN   \n",
              "4                            4                                   NaN   \n",
              "...                        ...                                   ...   \n",
              "167995                     346                              0.065126   \n",
              "167996                     347                                   NaN   \n",
              "167997                     348                              0.094700   \n",
              "167998                     349                                   NaN   \n",
              "167999                     350                              0.081015   \n",
              "\n",
              "feature_group  fake_causes_real_effects_fake_target_cause  \\\n",
              "0                                                     NaN   \n",
              "1                                                     NaN   \n",
              "2                                                     NaN   \n",
              "3                                                     NaN   \n",
              "4                                                     NaN   \n",
              "...                                                   ...   \n",
              "167995                                                NaN   \n",
              "167996                                                NaN   \n",
              "167997                                                NaN   \n",
              "167998                                                NaN   \n",
              "167999                                                NaN   \n",
              "\n",
              "feature_group  fake_causes_real_effects_real_target  \\\n",
              "0                                               NaN   \n",
              "1                                               NaN   \n",
              "2                                               NaN   \n",
              "3                                               NaN   \n",
              "4                                               NaN   \n",
              "...                                             ...   \n",
              "167995                                          NaN   \n",
              "167996                                     0.034478   \n",
              "167997                                          NaN   \n",
              "167998                                     0.043508   \n",
              "167999                                          NaN   \n",
              "\n",
              "feature_group  fake_causes_real_effects_real_target_cause  fake_target  \\\n",
              "0                                                     NaN     0.010056   \n",
              "1                                                     NaN     0.004665   \n",
              "2                                                     NaN     0.043046   \n",
              "3                                                     NaN     0.015118   \n",
              "4                                                     NaN     0.006803   \n",
              "...                                                   ...          ...   \n",
              "167995                                                NaN          NaN   \n",
              "167996                                                NaN          NaN   \n",
              "167997                                                NaN          NaN   \n",
              "167998                                                NaN          NaN   \n",
              "167999                                                NaN          NaN   \n",
              "\n",
              "feature_group  real_causes_fake_effects_fake_target  \\\n",
              "0                                               NaN   \n",
              "1                                               NaN   \n",
              "2                                               NaN   \n",
              "3                                               NaN   \n",
              "4                                               NaN   \n",
              "...                                             ...   \n",
              "167995                                          NaN   \n",
              "167996                                          NaN   \n",
              "167997                                          NaN   \n",
              "167998                                          NaN   \n",
              "167999                                          NaN   \n",
              "\n",
              "feature_group  real_causes_fake_effects_fake_target_effect  \\\n",
              "0                                                      NaN   \n",
              "1                                                      NaN   \n",
              "2                                                      NaN   \n",
              "3                                                      NaN   \n",
              "4                                                      NaN   \n",
              "...                                                    ...   \n",
              "167995                                            0.065126   \n",
              "167996                                                 NaN   \n",
              "167997                                            0.094700   \n",
              "167998                                                 NaN   \n",
              "167999                                            0.081015   \n",
              "\n",
              "feature_group  real_causes_fake_effects_real_target  \\\n",
              "0                                               NaN   \n",
              "1                                               NaN   \n",
              "2                                               NaN   \n",
              "3                                               NaN   \n",
              "4                                               NaN   \n",
              "...                                             ...   \n",
              "167995                                          NaN   \n",
              "167996                                          NaN   \n",
              "167997                                          NaN   \n",
              "167998                                          NaN   \n",
              "167999                                          NaN   \n",
              "\n",
              "feature_group  real_causes_fake_effects_real_target_effect  real_target  \n",
              "0                                                      NaN     0.023626  \n",
              "1                                                      NaN     0.020725  \n",
              "2                                                      NaN     0.116128  \n",
              "3                                                      NaN     0.021263  \n",
              "4                                                      NaN     0.006771  \n",
              "...                                                    ...          ...  \n",
              "167995                                                 NaN          NaN  \n",
              "167996                                            0.034478          NaN  \n",
              "167997                                                 NaN          NaN  \n",
              "167998                                            0.043508          NaN  \n",
              "167999                                                 NaN          NaN  \n",
              "\n",
              "[168000 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7458ee0d-04bd-4f5a-be4e-71fcff3688b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>feature_group</th>\n",
              "      <th>causal</th>\n",
              "      <th>sample</th>\n",
              "      <th>causal_type</th>\n",
              "      <th>feature_name</th>\n",
              "      <th>index_in_sample</th>\n",
              "      <th>fake_causes_real_effects_fake_target</th>\n",
              "      <th>fake_causes_real_effects_fake_target_cause</th>\n",
              "      <th>fake_causes_real_effects_real_target</th>\n",
              "      <th>fake_causes_real_effects_real_target_cause</th>\n",
              "      <th>fake_target</th>\n",
              "      <th>real_causes_fake_effects_fake_target</th>\n",
              "      <th>real_causes_fake_effects_fake_target_effect</th>\n",
              "      <th>real_causes_fake_effects_real_target</th>\n",
              "      <th>real_causes_fake_effects_real_target_effect</th>\n",
              "      <th>real_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.010056</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.023626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.004665</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.020725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.043046</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.116128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.015118</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.021263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hours_per_week</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006803</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167995</th>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>target_is_an_effect</td>\n",
              "      <td>relationship</td>\n",
              "      <td>346</td>\n",
              "      <td>0.065126</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.065126</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167996</th>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>target_is_an_effect</td>\n",
              "      <td>relationship</td>\n",
              "      <td>347</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.034478</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.034478</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167997</th>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>target_is_an_effect</td>\n",
              "      <td>relationship</td>\n",
              "      <td>348</td>\n",
              "      <td>0.094700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.094700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167998</th>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>target_is_an_effect</td>\n",
              "      <td>relationship</td>\n",
              "      <td>349</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.043508</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.043508</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167999</th>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>target_is_an_effect</td>\n",
              "      <td>relationship</td>\n",
              "      <td>350</td>\n",
              "      <td>0.081015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.081015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>168000 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7458ee0d-04bd-4f5a-be4e-71fcff3688b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7458ee0d-04bd-4f5a-be4e-71fcff3688b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7458ee0d-04bd-4f5a-be4e-71fcff3688b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30.03\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import igraph\n",
        "import itertools\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "class shapFlex_plus:\n",
        "    def __init__(self, explain,  model, predict_function, reference = None, target_features = None, \\\n",
        "                     causal = None, causal_weights = None, sample_size = None, use_future = None):\n",
        "        self.explain = explain\n",
        "        self.reference = reference if reference else explain\n",
        "        self.model = model\n",
        "        self.predict_function = predict_function\n",
        "        self.target_features = target_features if isinstance(target_features, pd.core.series.Series) else explain.columns.tolist()\n",
        "        self.causal = causal #if causal else None\n",
        "        self.causal_weights = causal_weights #if causal_weights else None\n",
        "        self.sample_size = sample_size if sample_size else 60\n",
        "        self.use_future = use_future if isinstance(target_features, pd.core.series.Series) else False\n",
        "        \n",
        "        self.n_features = self.explain.shape[1]\n",
        "        self.n_instances = self.reference.shape[0]\n",
        "\n",
        "        self.causal_graph = igraph.Graph.DataFrame(self.causal, directed=True) if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v for v in self.causal_graph.vs] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.each_node_causes = {v['name']: [succ['name'] for succ in v.successors()] for v in self.nodes if v.successors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# надо уточнить, мб здесь не только \"прямые\" successors и predecessors ищутся \n",
        "        self.each_node_is_an_effect_from = {v['name']: [pred['name'] for pred in v.predecessors()] for v in self.nodes if v.predecessors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# но и вообще все\n",
        "        # имена, кажется, уже прописаны автоматически\n",
        "        self.causal_nodes = [v for v in self.each_node_causes.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.effect_nodes = [v for v in self.each_node_is_an_effect_from.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v['name'] for v in self.nodes] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "\n",
        "    @staticmethod\n",
        "    def unlist_df(data):\n",
        "      unlisted_df = pd.Series(\n",
        "                  data,\n",
        "                  index=[\n",
        "                  index_col + index_row for index_col, index_row in itertools.product(\n",
        "                      [str(x) for x in range(data.shape[0])], \n",
        "                      [str(x) for x in data.columns])]\n",
        "              )\n",
        "      return unlisted_df\n",
        "      \n",
        "    def loop_over_monte_carlo_samples(self):\n",
        "      i_size = self.sample_size\n",
        "      j_size = len(self.target_features)\n",
        "      data_sample = []\n",
        "\n",
        "      for i in range(i_size):\n",
        "        reference_index = np.random.choice(np.arange(0, self.n_features ), size=1, replace=False)\n",
        "        feature_indices_random = np.random.choice(np.arange(0, self.n_features), size=self.n_features, replace=False)\n",
        "        # r индексация стартует с 1 а питон с 0 поэтому нам нужно вычиать 1 или ставить по верхней границе индексы в зависимости от функции вызова\n",
        "        feature_names_random = self.explain.columns[feature_indices_random].values\n",
        "        reference_instance = self.reference.iloc[reference_index, feature_indices_random]\n",
        "        #feature_indices_random это вектор индексов\n",
        "        explain_instances = self.explain.iloc[:, feature_indices_random]\n",
        "        data_sample_feature = []\n",
        "        for j in range(j_size):\n",
        "          target_feature_index =  self.explain.columns.get_loc(self.target_features[j])\n",
        "          target_feature_index_shuffled = list(self.explain.columns.values[feature_indices_random]).index(self.target_features[j])\n",
        "          #if True:\n",
        "          #  print(target_feature_index)\n",
        "          # target_feature_index = (self.explain.columns == self.target_features[j])\n",
        "          # target_feature_index_shuffled = (self.explain.columns[feature_indices_random] == self.target_features[j])\n",
        "          \n",
        "          if self.target_features[j] in self.nodes:\n",
        "            #unlist как я понял, вытягивает все данные в один длинный вектор, присваивает индексы как название колонки + название строки\n",
        "            #предположу, что each_node_causes это pd.DataFrame()\n",
        "            target_feature_causes_these_features =  [self.target_features[j]] + self.each_node_causes.get(self.target_features[j], []) \n",
        "            target_feature_is_caused_by =  [self.target_features[j]] + self.each_node_is_an_effect_from.get(self.target_features[j], []) \n",
        "            target_index = target_feature_index_shuffled\n",
        "            #отмечаем те значения feature_names_random которые равны последнему значению \n",
        "            #target_feature_is_caused_by. target_feature_is_caused_by вроде как вектор\n",
        "            #вернуться должно число. Если вдруг окажется, что датафрейм, -1 элемент будет строка, \n",
        "            #надо заменить на индексацию на iloc, == на .isin\n",
        "            causes_indices = np.where(np.in1d(feature_names_random, target_feature_is_caused_by[1:]))[0]\n",
        "            effects_indices  = np.where(np.in1d(feature_names_random, target_feature_causes_these_features[1:]))[0]\n",
        "            sample_indices = feature_indices_random[~np.isin(feature_indices_random, \n",
        "                np.concatenate([[target_index], causes_indices, effects_indices]))]\n",
        "            #c() вроде как склеивает вектор(ы) и переменные\n",
        "            sample_real_indices = sample_indices[sample_indices < target_index]  # Not in causal diagram, feature data from 'explain'.\n",
        "            sample_fake_indices = sample_indices[sample_indices > target_index]  # Not in causal diagram, feature data from 'reference'.\n",
        "\n",
        "            feature_indices_real_causes_real_effects = np.concatenate([sample_real_indices, causes_indices, effects_indices, [target_index], sample_fake_indices])\n",
        "            feature_indices_real_causes_fake_effects = np.concatenate([sample_real_indices, causes_indices, [target_index], effects_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_real_effects = np.concatenate([sample_real_indices, effects_indices, [target_index], causes_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_fake_effects = np.concatenate([sample_real_indices, [target_index], causes_indices, effects_indices, sample_fake_indices])\n",
        "          \n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            explain_instance_real_target = explain_instances.copy()\n",
        "\n",
        "            # Only create a Frankenstein instance if the target is not the last feature and there is actually\n",
        "            # one or more features to the right of the target to replace with the reference.\n",
        "            if (target_feature_index_shuffled < self.n_features):\n",
        "              #x = reference_instance.iloc[:, target_feature_index_shuffled: ]\n",
        "              explain_instance_real_target.iloc[:, target_feature_index_shuffled+1: ] =\\\n",
        "                 pd.concat([reference_instance.iloc[:, target_feature_index_shuffled+1: ]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              \n",
        "            # These instances are otherwise the same as the Frankenstein instance created above with the\n",
        "            # exception that the target feature is now replaced with the target feature in the random reference\n",
        "            # instance. The difference in model predictions between these two Frankenstein instances is\n",
        "            # what gives us the stochastic Shapley value approximation.\n",
        "            explain_instance_fake_target = explain_instance_real_target.copy()\n",
        "            \n",
        "            # ОНИ ПОЧЕМУ ТО ВЫШЛИ ОДИНАКОВЫЕ, ЭТО ОК?\n",
        "            explain_instance_fake_target.iloc[:, [target_feature_index_shuffled]] =\\\n",
        "               pd.concat([reference_instance.iloc[:, [target_feature_index_shuffled]]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "          \n",
        "          else:\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_real_causes_fake_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "                \n",
        "\n",
        "              explain_instance_real_causes_fake_effects_fake_target = explain_instance_real_causes_fake_effects_real_target\n",
        "              explain_instance_real_causes_fake_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features+1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              \n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause = explain_instance_fake_causes_real_effects_real_target_cause\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target_effect.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if (target_index_temp < self.n_features):\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              \n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect = explain_instance_real_causes_fake_effects_real_target_effect\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.iloc[:, target_index_temp] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_fake_causes_real_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "                \n",
        "\n",
        "              explain_instance_fake_causes_real_effects_fake_target = explain_instance_fake_causes_real_effects_real_target\n",
        "              explain_instance_fake_causes_real_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "\n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            #магическим образом две нижеследующие строчки возвращают датафрейм к старому виду\n",
        "            explain_instance_real_target = explain_instance_real_target.loc[:, self.explain.columns]\n",
        "            explain_instance_fake_target = explain_instance_fake_target.loc[:, self.explain.columns]\n",
        "            data_explain_instance = pd.concat([explain_instance_real_target, explain_instance_fake_target], axis=0).reset_index(drop=True)#, ignore_index=True)\n",
        "            #вот тут не совсем понятно, индекс это число или строка, индексы в data_explain_instance это числа или строки? в любом случае, при запуске можно починить\n",
        "            data_explain_instance['index_in_sample'] = np.tile(np.arange(0, self.explain.shape[0]), 2) \n",
        "            data_explain_instance['feature_group'] = np.repeat(['real_target', 'fake_target'], repeats=self.explain.shape[0])\n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 0\n",
        "            data_explain_instance['causal_type'] = None\n",
        "\n",
        "          else:\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause], axis=0\n",
        "              ).reset_index(drop=True)\n",
        "              data_explain_instance['index_in_sample'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",\n",
        "                                                          \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_a_cause\"\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index_in_sample'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",\n",
        "                                                          \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_an_effect\"\n",
        "\n",
        "            if (self.target_features[j] in self.causal_nodes) and (self.target_features[j] in self.effect_nodes):\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause,\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index_in_sample'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 8)  # Eight Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\n",
        "                \"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",  # Target is a causal node.\n",
        "                \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\",  # Target is a causal node.\n",
        "                \"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",  # Target is an effect node.\n",
        "                \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"  # Target is an effect node.\n",
        "                ]),\n",
        "              self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = np.tile(pd.Series([\n",
        "                \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\",\n",
        "                \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\"]\n",
        "              ),\n",
        "              self.explain.shape[0])\n",
        "            \n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 1\n",
        "\n",
        "          data_explain_instance['sample'] = i\n",
        "          data_sample_feature.append(data_explain_instance)\n",
        "\n",
        "        data_sample.append(data_sample_feature)\n",
        "\n",
        "      data_sample = pd.concat([pd.concat(data_sample_i, axis=0) for data_sample_i in data_sample], axis=0).reset_index(drop=True)\n",
        "      return data_sample\n",
        "\n",
        "    def predict_shapFlex(self, data_predict):\n",
        "      '''есть self.reference, self.model, self.predict_function, self.n_features, self.causal, self.causal_weights'''\n",
        "      data_model = data_predict.iloc[:, :self.n_features].copy()\n",
        "      data_meta = data_predict.iloc[:, self.n_features:].copy()\n",
        "      data_predicted = pd.DataFrame(predict_function(self.model, data_model), index=data_model.index)\n",
        "      data_predicted = pd.concat([data_meta, data_predicted], axis=1)\n",
        "      #мб придется править, в зависимости от формата входных данных (вектор-строка/-столбец), пока результат по всем измерениям, скаляр\n",
        "      intercept = predict_function(self.model, self.reference).mean(skipna=True)\n",
        "      #вмест data.shape[1] взял -1\n",
        "      #костыль, не понимаю, что тут должно быть пока\n",
        "      user_fun_y_pred_name = data_predicted.columns[-1]\n",
        "      #тут нюанс: у них перед вэлью !! стоит, что значит значение которое за ними следует, это не значение, а expression, что бы это \n",
        "      # ни значило, соответсвенно, может беда быть\n",
        "      #data_predicted = pd.concat([\n",
        "      #  data_predicted.drop('feature_group', axis=1), \n",
        "      #  data_predicted.reset_index().pivot_table(index='index', columns=[ 'feature_group'], values=user_fun_y_pred_name)\n",
        "      #  ], axis=1)\n",
        "\n",
        "      data_predicted = data_predicted.pivot_table(\n",
        "        index=['causal_type', 'sample', 'causal', 'feature_name'],#set(data_predicted.columns) - set(['index', 'feature_group', user_fun_y_pred_name]),\n",
        "        columns=['feature_group'],\n",
        "        values=user_fun_y_pred_name\n",
        "      ).reset_index()\n",
        "      data_non_causal = data_predicted.loc[data_predicted['causal']==0]\n",
        "      data_non_causal['shap_effect'] = data_non_causal['real_target'] - data_non_causal['fake_target']\n",
        "      data_causal = data_predicted.loc[data_predicted['causal']==1]\n",
        "\n",
        "      if isinstance(self.causal, pd.core.frame.DataFrame):\n",
        "        pass\n",
        "\n",
        "      data_predicted = pd.concat([data_causal, data_non_causal], ignore_index=True, axis=0)\n",
        "      data_predicted = data_predicted.loc[:, ['index_in_sample', 'sample', 'feature_name', 'shap_effect']]\n",
        "\n",
        "      data_predicted = data_predicted.reset_index().dropna(axis=0).groupby(['index_in_sample', 'feature_name']).agg({'shap_effect': [np.std, np.mean]})\n",
        "      data_predicted[('shap_effect', 'intercept')] = intercept[0]\n",
        "\n",
        "      return data_predicted\n",
        "\n",
        "    def forward(self):\n",
        "      data_predict = self.loop_over_monte_carlo_samples()\n",
        "      data_predicted = self.predict_shapFlex(data_predict)\n",
        "      return data_predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('https://kolodezev.ru/download/data_adult.csv', index_col=0)\n",
        "outcome_name = 'income'\n",
        "outcome_col = pd.Series(data.columns)[data.columns==outcome_name].index[0]\n",
        "X, y = data.drop(outcome_name, axis=1), data[outcome_name].values\n",
        "cat_features = [inx for inx, value in zip(X.dtypes.index, X.dtypes) if value =='object']\n",
        "model = CatBoostClassifier()\n",
        "model.fit(X, y, cat_features=cat_features, verbose=False)\n",
        "def predict_function(model, data):\n",
        "  #pd.DataFrame(model.predict_proba(X)).loc[:, 0][9] если запустить будет результат 0.98, что соответствует\n",
        "  #выводу для 9 номера который равен 0.98, неважно какой алгоритм, такая высокая степень уверенности\n",
        "  #позволяет идентифицировать выводимую колонку однозначно\n",
        "  return pd.DataFrame(model.predict_proba(data)[:, [0]])\n",
        "\n",
        "\n",
        "explain, reference = data.iloc[:300, :data.shape[1]-1], data.iloc[:, :data.shape[1]-1]\n",
        "sample_size = 10\n",
        "target_features = pd.Series([\"marital_status\", \"education\", \"relationship\",  \"native_country\",\n",
        "                     \"age\", \"sex\", \"race\", \"hours_per_week\"])\n",
        "causal = pd.DataFrame(\n",
        "  dict(cause=pd.Series([\"age\", \"sex\", \"race\", \"native_country\",\n",
        "              \"age\", \"sex\", \"race\", \"native_country\", \"age\",\n",
        "              \"sex\", \"race\", \"native_country\"]),\n",
        "  effect = pd.Series(np.concatenate([np.tile(\"marital_status\", 4), np.tile(\"education\", 4), np.tile(\"relationship\", 4)])))\n",
        ")\n",
        "exmpl_of_test = shapFlex_plus(explain,  model, predict_function, target_features=pd.Series([\"marital_status\", \"education\", \"relationship\", \"native_country\",\n",
        "\"age\", \"sex\", \"race\", \"hours_per_week\"]), causal=causal, causal_weights = [0.5 for x in range(len(causal))])\n",
        "data_predict = exmpl_of_test.loop_over_monte_carlo_samples()\n",
        "data_predicted = exmpl_of_test.predict_shapFlex(data_predict)\n",
        "#print(data_predicted)"
      ],
      "metadata": {
        "id": "DO3mudke7IeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#06.04\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import igraph\n",
        "import itertools\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "class shapFlex_plus:\n",
        "    def __init__(self, explain,  model, predict_function, reference = None, target_features = None, \\\n",
        "                     causal = None, causal_weights = None, sample_size = None, use_future = None):\n",
        "        self.explain = explain\n",
        "        self.reference = reference if reference else explain\n",
        "        self.model = model\n",
        "        self.predict_function = predict_function\n",
        "        self.target_features = target_features if isinstance(target_features, pd.core.series.Series) else explain.columns.tolist()\n",
        "        self.causal = causal #if causal else None\n",
        "        self.causal_weights = causal_weights #if causal_weights else None\n",
        "        self.sample_size = sample_size if sample_size else 60\n",
        "        self.use_future = use_future if isinstance(target_features, pd.core.series.Series) else False\n",
        "        \n",
        "        self.n_features = self.explain.shape[1]\n",
        "        self.n_instances = self.reference.shape[0]\n",
        "\n",
        "        self.causal_graph = igraph.Graph.DataFrame(self.causal, directed=True) if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v for v in self.causal_graph.vs] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.each_node_causes = {v['name']: [succ['name'] for succ in v.successors()] for v in self.nodes if v.successors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# надо уточнить, мб здесь не только \"прямые\" successors и predecessors ищутся \n",
        "        self.each_node_is_an_effect_from = {v['name']: [pred['name'] for pred in v.predecessors()] for v in self.nodes if v.predecessors()} if isinstance(self.causal, pd.core.frame.DataFrame) else [None]# но и вообще все\n",
        "        # имена, кажется, уже прописаны автоматически\n",
        "        self.causal_nodes = [v for v in self.each_node_causes.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.effect_nodes = [v for v in self.each_node_is_an_effect_from.keys()] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "        self.nodes = [v['name'] for v in self.nodes] if isinstance(self.causal, pd.core.frame.DataFrame) else [None]\n",
        "\n",
        "    @staticmethod\n",
        "    def unlist_df(data):\n",
        "      unlisted_df = pd.Series(\n",
        "                  data,\n",
        "                  index=[\n",
        "                  index_col + index_row for index_col, index_row in itertools.product(\n",
        "                      [str(x) for x in range(data.shape[0])], \n",
        "                      [str(x) for x in data.columns])]\n",
        "              )\n",
        "      return unlisted_df\n",
        "      \n",
        "    def loop_over_monte_carlo_samples(self):\n",
        "      i_size = self.sample_size\n",
        "      j_size = len(self.target_features)\n",
        "      data_sample = []\n",
        "\n",
        "      for i in range(i_size):\n",
        "        reference_index = np.random.choice(np.arange(0, self.n_features ), size=1, replace=False)\n",
        "        feature_indices_random = np.random.choice(np.arange(0, self.n_features), size=self.n_features, replace=False)\n",
        "        # r индексация стартует с 1 а питон с 0 поэтому нам нужно вычиать 1 или ставить по верхней границе индексы в зависимости от функции вызова\n",
        "        feature_names_random = self.explain.columns[feature_indices_random].values\n",
        "        reference_instance = self.reference.iloc[reference_index, feature_indices_random]\n",
        "        #feature_indices_random это вектор индексов\n",
        "        explain_instances = self.explain.iloc[:, feature_indices_random]\n",
        "        data_sample_feature = []\n",
        "        for j in range(j_size):\n",
        "          target_feature_index =  self.explain.columns.get_loc(self.target_features[j])\n",
        "          target_feature_index_shuffled = list(self.explain.columns.values[feature_indices_random]).index(self.target_features[j])\n",
        "          #if True:\n",
        "          #  print(target_feature_index)\n",
        "          # target_feature_index = (self.explain.columns == self.target_features[j])\n",
        "          # target_feature_index_shuffled = (self.explain.columns[feature_indices_random] == self.target_features[j])\n",
        "          \n",
        "          if self.target_features[j] in self.nodes:\n",
        "            #unlist как я понял, вытягивает все данные в один длинный вектор, присваивает индексы как название колонки + название строки\n",
        "            #предположу, что each_node_causes это pd.DataFrame()\n",
        "            target_feature_causes_these_features =  [self.target_features[j]] + self.each_node_causes.get(self.target_features[j], []) \n",
        "            target_feature_is_caused_by =  [self.target_features[j]] + self.each_node_is_an_effect_from.get(self.target_features[j], []) \n",
        "            target_index = target_feature_index_shuffled\n",
        "            #отмечаем те значения feature_names_random которые равны последнему значению \n",
        "            #target_feature_is_caused_by. target_feature_is_caused_by вроде как вектор\n",
        "            #вернуться должно число. Если вдруг окажется, что датафрейм, -1 элемент будет строка, \n",
        "            #надо заменить на индексацию на iloc, == на .isin\n",
        "            causes_indices = np.where(np.in1d(feature_names_random, target_feature_is_caused_by[1:]))[0]\n",
        "            effects_indices  = np.where(np.in1d(feature_names_random, target_feature_causes_these_features[1:]))[0]\n",
        "            sample_indices = feature_indices_random[~np.isin(feature_indices_random, \n",
        "                np.concatenate([[target_index], causes_indices, effects_indices]))]\n",
        "            #c() вроде как склеивает вектор(ы) и переменные\n",
        "            sample_real_indices = sample_indices[sample_indices < target_index]  # Not in causal diagram, feature data from 'explain'.\n",
        "            sample_fake_indices = sample_indices[sample_indices > target_index]  # Not in causal diagram, feature data from 'reference'.\n",
        "\n",
        "            feature_indices_real_causes_real_effects = np.concatenate([sample_real_indices, causes_indices, effects_indices, [target_index], sample_fake_indices])\n",
        "            feature_indices_real_causes_fake_effects = np.concatenate([sample_real_indices, causes_indices, [target_index], effects_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_real_effects = np.concatenate([sample_real_indices, effects_indices, [target_index], causes_indices, sample_fake_indices])\n",
        "            feature_indices_fake_causes_fake_effects = np.concatenate([sample_real_indices, [target_index], causes_indices, effects_indices, sample_fake_indices])\n",
        "          \n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            explain_instance_real_target = explain_instances.copy()\n",
        "\n",
        "            # Only create a Frankenstein instance if the target is not the last feature and there is actually\n",
        "            # one or more features to the right of the target to replace with the reference.\n",
        "            if (target_feature_index_shuffled < self.n_features):\n",
        "              #x = reference_instance.iloc[:, target_feature_index_shuffled: ]\n",
        "              explain_instance_real_target.iloc[:, target_feature_index_shuffled+1: ] =\\\n",
        "                 pd.concat([reference_instance.iloc[:, target_feature_index_shuffled+1: ]] * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "              \n",
        "            # These instances are otherwise the same as the Frankenstein instance created above with the\n",
        "            # exception that the target feature is now replaced with the target feature in the random reference\n",
        "            # instance. The difference in model predictions between these two Frankenstein instances is\n",
        "            # what gives us the stochastic Shapley value approximation.\n",
        "            explain_instance_fake_target = explain_instance_real_target.copy()\n",
        "            \n",
        "            # ОНИ ПОЧЕМУ ТО ВЫШЛИ ОДИНАКОВЫЕ, ЭТО ОК?\n",
        "            explain_instance_fake_target.iloc[:, [target_feature_index_shuffled]] =\\\n",
        "               pd.concat([reference_instance.iloc[:, [target_feature_index_shuffled]]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "          \n",
        "          else:\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_real_causes_fake_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "                \n",
        "\n",
        "              explain_instance_real_causes_fake_effects_fake_target = explain_instance_real_causes_fake_effects_real_target\n",
        "              explain_instance_real_causes_fake_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]]  * self.explain.shape[0], axis=0).reset_index(drop=True)\n",
        "\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features+1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              \n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause = explain_instance_fake_causes_real_effects_real_target_cause\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              reference_instance_real_causes_fake_effects = reference_instance.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect = explain_instances.iloc[:, feature_indices_real_causes_fake_effects]\n",
        "\n",
        "              target_index_temp = explain_instance_real_causes_fake_effects_real_target_effect.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if (target_index_temp < self.n_features):\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              \n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect = explain_instance_real_causes_fake_effects_real_target_effect\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.iloc[:, target_index_temp] =\\\n",
        "                pd.concat([reference_instance_real_causes_fake_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "              reference_instance_fake_causes_real_effects = reference_instance.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              explain_instance_fake_causes_real_effects_real_target = explain_instances.iloc[:, feature_indices_fake_causes_real_effects]\n",
        "              target_index_temp = explain_instance_fake_causes_real_effects_real_target.columns.get_loc(self.target_features[j])\n",
        "\n",
        "              if target_index_temp < self.n_features:\n",
        "                explain_instance_fake_causes_real_effects_real_target.iloc[:, target_index_temp + 1: self.n_features + 1] =\\\n",
        "                pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp + 1: self.n_features + 1]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "                \n",
        "\n",
        "              explain_instance_fake_causes_real_effects_fake_target = explain_instance_fake_causes_real_effects_real_target\n",
        "              explain_instance_fake_causes_real_effects_fake_target.iloc[:, target_index_temp] =\\\n",
        "              pd.concat([reference_instance_fake_causes_real_effects.iloc[:, target_index_temp]]*self.explain.shape[0],\n",
        "                axis=0).reset_index(drop=True)\n",
        "\n",
        "          if not self.target_features[j] in self.nodes:\n",
        "            #магическим образом две нижеследующие строчки возвращают датафрейм к старому виду\n",
        "            explain_instance_real_target = explain_instance_real_target.loc[:, self.explain.columns]\n",
        "            explain_instance_fake_target = explain_instance_fake_target.loc[:, self.explain.columns]\n",
        "            data_explain_instance = pd.concat([explain_instance_real_target, explain_instance_fake_target], axis=0).reset_index(drop=True)#, ignore_index=True)\n",
        "            #вот тут не совсем понятно, индекс это число или строка, индексы в data_explain_instance это числа или строки? в любом случае, при запуске можно починить\n",
        "            data_explain_instance['index_in_sample'] = np.tile(np.arange(0, self.explain.shape[0]), 2) \n",
        "            data_explain_instance['feature_group'] = np.repeat(['real_target', 'fake_target'], repeats=self.explain.shape[0])\n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 0\n",
        "            data_explain_instance['causal_type'] = None\n",
        "\n",
        "          else:\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target_cause.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target_cause.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_real_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect =\\\n",
        "              explain_instance_real_causes_fake_effects_fake_target_effect.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_real_target =\\\n",
        "              explain_instance_fake_causes_real_effects_real_target.loc[:, self.explain.columns]\n",
        "              explain_instance_fake_causes_real_effects_fake_target =\\\n",
        "              explain_instance_fake_causes_real_effects_fake_target.loc[:, self.explain.columns]\n",
        "\n",
        "            if self.target_features[j] in self.causal_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause], axis=0\n",
        "              ).reset_index(drop=True)\n",
        "              data_explain_instance['index_in_sample'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",\n",
        "                                                          \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_a_cause\"\n",
        "\n",
        "            if self.target_features[j] in self.effect_nodes:\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index_in_sample'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 4)  # Four Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",\n",
        "                                                          \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"]),\n",
        "                                                        self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = \"target_is_an_effect\"\n",
        "\n",
        "            if (self.target_features[j] in self.causal_nodes) and (self.target_features[j] in self.effect_nodes):\n",
        "              data_explain_instance = pd.concat([\n",
        "                explain_instance_real_causes_fake_effects_real_target,\n",
        "                explain_instance_real_causes_fake_effects_fake_target,\n",
        "                explain_instance_fake_causes_real_effects_real_target_cause,\n",
        "                explain_instance_fake_causes_real_effects_fake_target_cause,\n",
        "                explain_instance_real_causes_fake_effects_real_target_effect,\n",
        "                explain_instance_real_causes_fake_effects_fake_target_effect,\n",
        "                explain_instance_fake_causes_real_effects_real_target,\n",
        "                explain_instance_fake_causes_real_effects_fake_target\n",
        "              ], axis=0).reset_index(drop=True)\n",
        "              data_explain_instance['index_in_sample'] = np.tile(np.arange(1, self.explain.shape[0] + 1), 8)  # Eight Frankenstein instances per explained instance.\n",
        "              data_explain_instance['feature_group'] = np.tile(pd.Series([\n",
        "                \"real_causes_fake_effects_real_target\", \"real_causes_fake_effects_fake_target\",  # Target is a causal node.\n",
        "                \"fake_causes_real_effects_real_target_cause\", \"fake_causes_real_effects_fake_target_cause\",  # Target is a causal node.\n",
        "                \"real_causes_fake_effects_real_target_effect\", \"real_causes_fake_effects_fake_target_effect\",  # Target is an effect node.\n",
        "                \"fake_causes_real_effects_real_target\", \"fake_causes_real_effects_fake_target\"  # Target is an effect node.\n",
        "                ]),\n",
        "              self.explain.shape[0])\n",
        "              data_explain_instance['causal_type'] = np.tile(pd.Series([\n",
        "                \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\", \"target_is_a_cause\",\n",
        "                \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\", \"target_is_an_effect\"]\n",
        "              ),\n",
        "              self.explain.shape[0])\n",
        "            \n",
        "            data_explain_instance['feature_name'] = self.target_features[j]\n",
        "            data_explain_instance['causal'] = 1\n",
        "\n",
        "          data_explain_instance['sample'] = i\n",
        "          data_sample_feature.append(data_explain_instance)\n",
        "\n",
        "        data_sample.append(data_sample_feature)\n",
        "\n",
        "      data_sample = pd.concat([pd.concat(data_sample_i, axis=0) for data_sample_i in data_sample], axis=0).reset_index(drop=True)\n",
        "      return data_sample\n",
        "\n",
        "    def predict_shapFlex(self, data_predict):\n",
        "      '''есть self.reference, self.model, self.predict_function, self.n_features, self.causal, self.causal_weights'''\n",
        "      data_model = data_predict.iloc[:, :self.n_features].copy()\n",
        "      data_meta = data_predict.iloc[:, self.n_features:].copy()\n",
        "      data_predicted = pd.DataFrame(predict_function(self.model, data_model), index=data_model.index)\n",
        "      data_predicted = pd.concat([data_meta, data_predicted], axis=1)\n",
        "      #мб придется править, в зависимости от формата входных данных (вектор-строка/-столбец), пока результат по всем измерениям, скаляр\n",
        "      intercept = predict_function(self.model, self.reference).mean(skipna=True)\n",
        "      #вмест data.shape[1] взял -1\n",
        "      #костыль, не понимаю, что тут должно быть пока\n",
        "      user_fun_y_pred_name = data_predicted.columns[-1]\n",
        "      #тут нюанс: у них перед вэлью !! стоит, что значит значение которое за ними следует, это не значение, а expression, что бы это \n",
        "      # ни значило, соответсвенно, может беда быть\n",
        "      #data_predicted = pd.concat([\n",
        "      #  data_predicted.drop('feature_group', axis=1), \n",
        "      #  data_predicted.reset_index().pivot_table(index='index', columns=[ 'feature_group'], values=user_fun_y_pred_name)\n",
        "      #  ], axis=1)\n",
        "      variables_of_interest = list(set(data_predicted.columns) - set(['feature_group', user_fun_y_pred_name]))\n",
        "      data_predicted.loc[:, variables_of_interest] =\\\n",
        "        data_predicted.loc[:, variables_of_interest].fillna(-99999)\n",
        "      data_predicted = data_predicted.pivot_table(\n",
        "        index=set(data_predicted.columns) - set(['feature_group', user_fun_y_pred_name]),\n",
        "        columns=['feature_group'],\n",
        "        values=user_fun_y_pred_name\n",
        "      ).reset_index()\n",
        "      \n",
        "      data_non_causal = data_predicted.loc[data_predicted['causal']==0]\n",
        "      data_non_causal['shap_effect'] = data_non_causal['real_target'] - data_non_causal['fake_target']\n",
        "      data_causal = data_predicted.loc[data_predicted['causal']==1]\n",
        "\n",
        "      if isinstance(self.causal, pd.core.frame.DataFrame):\n",
        "        data_target_is_a_cause = data_causal[data_causal['causal_type'] == 'target_is_a_cause']\n",
        "        data_target_is_an_effect = data_causal[data_causal['causal_type'] == 'target_is_an_effect']\n",
        "\n",
        "        data_target_is_a_cause['shap_u_1_12'] = data_target_is_a_cause.loc[:, 'real_causes_fake_effects_real_target'] -\\\n",
        "          data_target_is_a_cause.loc[:, 'real_causes_fake_effects_fake_target']\n",
        "        data_target_is_a_cause['shap_u_1_21'] = data_target_is_a_cause.loc[:, 'fake_causes_real_effects_real_target_cause'] -\\\n",
        "          data_target_is_a_cause.loc[:, 'fake_causes_real_effects_fake_target_cause']\n",
        "        data_target_is_an_effect['shap_u_2_12'] = data_target_is_an_effect.loc[:, 'real_causes_fake_effects_real_target_effect'] -\\\n",
        "          data_target_is_an_effect.loc[:, 'real_causes_fake_effects_fake_target_effect']\n",
        "        data_target_is_an_effect['shap_u_2_21'] = data_target_is_an_effect.loc[:, 'fake_causes_real_effects_real_target'] -\\\n",
        "          data_target_is_an_effect.loc[:, 'fake_causes_real_effects_fake_target']\n",
        "        \n",
        "        data_weights = pd.concat([self.causal, pd.Series(self.causal_weights)], axis=1)\n",
        "        data_weights.columns = [\"target_is_a_cause\", \"target_is_an_effect\", \"weight\"]\n",
        "        ##52-53 не понял##\n",
        "        data_weights = pd.melt(data_weights,  id_vars='weight')\n",
        "        data_weights.columns= ['weight', \"causal_type\", \"feature_name\"]\n",
        "        data_weights = data_weights.groupby(['causal_type', 'feature_name']).apply(np.mean).reset_index()\n",
        "        data_target_is_a_cause = data_target_is_a_cause.merge(data_weights, on=['causal_type', 'feature_name'], how='left')\n",
        "        data_target_is_an_effect = data_target_is_an_effect.merge(data_weights, on=['causal_type', 'feature_name'], how='left')\n",
        "        #строка ниже: там почему-то лежит NaN, уточнить\n",
        "        shap_u_1 = np.sum(data_target_is_a_cause[['shap_u_1_12', 'shap_u_1_21']].values *\\\n",
        "           np.hstack([data_target_is_a_cause[['weight']].values, 1 - data_target_is_a_cause[['weight']].values]), axis=-1)\n",
        "        data_target_is_a_cause['shap_effect'] = shap_u_1\n",
        "        if data_target_is_an_effect.shape[0] > 0:\n",
        "          shap_u_2 = np.sum(data_target_is_an_effect[['shap_u_2_12', 'shap_u_2_21']].values *\\\n",
        "           np.hstack([data_target_is_an_effect[['weight']].values, 1 - data_target_is_an_effect[['weight']].values]), axis=-1)\n",
        "          data_target_is_an_effect['shap_effect'] = shap_u_2\n",
        "\n",
        "        data_causal = pd.concat([data_target_is_a_cause, data_target_is_an_effect], axis=0)\n",
        "        data_causal = data_causal.groupby(['index_in_sample', 'sample', 'feature_name']).apply(np.mean).reset_index()# мб докинуть условие на skipna\n",
        "\n",
        "      data_predicted = pd.concat([data_causal, data_non_causal], ignore_index=True, axis=0)\n",
        "      data_predicted = data_predicted.loc[:, ['index_in_sample', 'sample', 'feature_name', 'shap_effect']]\n",
        "\n",
        "      data_predicted = data_predicted.reset_index().dropna(axis=0).groupby(['index_in_sample', 'feature_name']).agg({'shap_effect': [np.std, np.mean]})\n",
        "      data_predicted[('shap_effect', 'intercept')] = intercept[0]\n",
        "\n",
        "      return data_predicted\n",
        "\n",
        "    def forward(self):\n",
        "      data_predict = self.loop_over_monte_carlo_samples()\n",
        "      data_predicted = self.predict_shapFlex(data_predict)\n",
        "      return data_predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('https://kolodezev.ru/download/data_adult.csv', index_col=0)\n",
        "outcome_name = 'income'\n",
        "outcome_col = pd.Series(data.columns)[data.columns==outcome_name].index[0]\n",
        "X, y = data.drop(outcome_name, axis=1), data[outcome_name].values\n",
        "cat_features = [inx for inx, value in zip(X.dtypes.index, X.dtypes) if value =='object']\n",
        "model = CatBoostClassifier()\n",
        "model.fit(X, y, cat_features=cat_features, verbose=False)\n",
        "def predict_function(model, data):\n",
        "  #pd.DataFrame(model.predict_proba(X)).loc[:, 0][9] если запустить будет результат 0.98, что соответствует\n",
        "  #выводу для 9 номера который равен 0.98, неважно какой алгоритм, такая высокая степень уверенности\n",
        "  #позволяет идентифицировать выводимую колонку однозначно\n",
        "  return pd.DataFrame(model.predict_proba(data)[:, [0]])\n",
        "\n",
        "\n",
        "explain, reference = data.iloc[:300, :data.shape[1]-1], data.iloc[:, :data.shape[1]-1]\n",
        "sample_size = 10\n",
        "target_features = pd.Series([\"marital_status\", \"education\", \"relationship\",  \"native_country\",\n",
        "                     \"age\", \"sex\", \"race\", \"hours_per_week\"])\n",
        "causal = pd.DataFrame(\n",
        "  dict(cause=pd.Series([\"age\", \"sex\", \"race\", \"native_country\",\n",
        "              \"age\", \"sex\", \"race\", \"native_country\", \"age\",\n",
        "              \"sex\", \"race\", \"native_country\"]),\n",
        "  effect = pd.Series(np.concatenate([np.tile(\"marital_status\", 4), np.tile(\"education\", 4), np.tile(\"relationship\", 4)])))\n",
        ")\n",
        "exmpl_of_test = shapFlex_plus(explain,  model, predict_function, target_features=pd.Series([\"marital_status\", \"education\", \"relationship\", \"native_country\",\n",
        "\"age\", \"sex\", \"race\", \"hours_per_week\"]), causal=causal, causal_weights = [0.5 for x in range(len(causal))])\n",
        "data_predict = exmpl_of_test.loop_over_monte_carlo_samples()\n",
        "data_predicted = exmpl_of_test.predict_shapFlex(data_predict)\n",
        "#print(data_predicted)"
      ],
      "metadata": {
        "id": "e428UEtzUR6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "shap_joint",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}